# -*- coding: utf-8 -*-
"""
ê³µê³µë„ì„œê´€ ì„¤ë¬¸ ë°ì´í„° ë¶„ì„ ë° ì‹œê°í™” ëŒ€ì‹œë³´ë“œ

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” Streamlitì„ ì‚¬ìš©í•˜ì—¬ ì„¤ë¬¸ì¡°ì‚¬ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³ ,
ë‹¤ì–‘í•œ ì‹œê°í™”ì™€ GPT ê¸°ë°˜ì˜ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•˜ëŠ” ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì…ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- ê¸°ë³¸ ì¸êµ¬í†µê³„ ë° ë§Œì¡±ë„ ë¬¸í•­ ë¶„ì„
- ì¤‘ë¶„ë¥˜ë³„, ì„¸ê·¸ë¨¼íŠ¸ë³„ ì‹¬í™” ë¶„ì„
- ìì—°ì–´ ì§ˆì˜ë¥¼ í†µí•œ ìë™ ë¶„ì„ ë° ì‹œê°í™”
- GPTë¥¼ í™œìš©í•œ í‚¤ì›Œë“œ ì¶”ì¶œ ë° ë¦¬í¬íŠ¸ ìƒì„±

ê°œì„  ì‚¬í•­:
- ì½”ë“œ êµ¬ì¡°í™”: ê¸°ëŠ¥ë³„(ìœ í‹¸ë¦¬í‹°, ë°ì´í„° ì²˜ë¦¬, ì‹œê°í™”, GPT ì—°ë™ ë“±) ëª¨ë“ˆí™”
- í•¨ìˆ˜ ì¬ì‚¬ìš©ì„± ì¦ëŒ€: ì¤‘ë³µë˜ëŠ” ì‹œê°í™” ë° ë°ì´í„° ì²˜ë¦¬ ë¡œì§ì„ ì¼ë°˜í™”ëœ í•¨ìˆ˜ë¡œ í†µí•©
- ê°€ë…ì„± í–¥ìƒ: ëª…í™•í•œ ë³€ìˆ˜ëª… ì‚¬ìš©, íƒ€ì… íŒíŠ¸ ì¶”ê°€, ìƒì„¸í•œ ì£¼ì„ ë° docstring ì‘ì„±
- ì•ˆì •ì„± ê°•í™”: êµ¬ì²´ì ì¸ ì˜ˆì™¸ ì²˜ë¦¬ ë° ì‚¬ìš©ì í”¼ë“œë°± ê°œì„ 
- Streamlit UX ê°œì„ : st.expander ë“±ì„ í™œìš©í•˜ì—¬ ê¹”ë”í•œ UI êµ¬ì„±
- ìƒìˆ˜ ê´€ë¦¬: í•˜ë“œì½”ë”©ëœ ë¬¸ìì—´ ë° ì„¤ì •ì„ ìƒìˆ˜ë¡œ ë¶„ë¦¬í•˜ì—¬ ê´€ë¦¬ ìš©ì´ì„± ì¦ëŒ€
"""

import time
import re
import json
import logging
from itertools import cycle
from typing import List, Dict, Any, Optional, Tuple

# ì„œë“œíŒŒí‹° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import numpy as np
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
import scipy.stats as stats
import streamlit as st
import streamlit.components.v1 as components
from openai import OpenAI

# -----------------------------------------------------------------------------
# 0. ì„¤ì • ë° ìƒìˆ˜ (Configuration & Constants)
# -----------------------------------------------------------------------------

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
# Streamlit secretsì—ì„œ API í‚¤ë¥¼ ì•ˆì „í•˜ê²Œ ë¡œë“œí•©ë‹ˆë‹¤.
try:
    client = OpenAI(api_key=st.secrets["openai"]["api_key"])
except (KeyError, FileNotFoundError):
    st.error("OpenAI API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Streamlit secretsì— `openai.api_key`ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    st.stop()


# --- ì‹œê°í™” ê´€ë ¨ ìƒìˆ˜ ---
DEFAULT_PALETTE = px.colors.qualitative.Plotly
LIKERT_COLORS = {
    1: "#d73027", 2: "#fc8d59", 3: "#fee090",
    4: "#dddddd", 5: "#91bfdb", 6: "#4575b4", 7: "#313695"
}

# --- ë°ì´í„° ë§¤í•‘ ê´€ë ¨ ìƒìˆ˜ ---
# ì¤‘ë¶„ë¥˜ ë§¤í•‘: ê° ì¤‘ë¶„ë¥˜ ì´ë¦„ê³¼ í•´ë‹¹ ì»¬ëŸ¼ì„ ì‹ë³„í•˜ëŠ” ëŒë‹¤ í•¨ìˆ˜ë¥¼ ì—°ê²°í•©ë‹ˆë‹¤.
MIDDLE_CATEGORY_MAPPING = {
    "ê³µê°„ ë° ì´ìš©í¸ì˜ì„±":       lambda col: str(col).startswith("Q1-"),
    "ì •ë³´ íšë“ ë° í™œìš©":       lambda col: str(col).startswith("Q2-"),
    "ì†Œí†µ ë° ì •ì±… í™œìš©":       lambda col: str(col).startswith("Q3-"),
    "ë¬¸í™”Â·êµìœ¡ í–¥ìœ ":         lambda col: str(col).startswith("Q4-"),
    "ì‚¬íšŒì  ê´€ê³„ í˜•ì„±":       lambda col: str(col).startswith("Q5-"),
    "ê°œì¸ì˜ ì‚¶ê³¼ ì—­ëŸ‰":       lambda col: str(col).startswith("Q6-"),
    "ë„ì„œê´€ì˜ ê³µìµì„± ë° ê¸°ì—¬ë„": lambda col: (str(col).startswith("Q7-") or str(col).startswith("Q8")),
    "ìì¹˜êµ¬ êµ¬ì„± ë¬¸í•­":        lambda col: str(col).startswith("Q9-D-3"),
}

# KDC ì£¼ì œ í‚¤ì›Œë“œ ë§¤í•‘
KDC_KEYWORD_MAP = {
    '000 ì´ë¥˜': ["ë°±ê³¼ì‚¬ì „", "ë„ì„œê´€", "ë…ì„œ", "ë¬¸í—Œì •ë³´", "ê¸°ë¡", "ì¶œíŒ", "ì„œì§€"],
    '100 ì² í•™': ["ì² í•™", "ëª…ìƒ", "ìœ¤ë¦¬", "ë…¼ë¦¬í•™", "ì‹¬ë¦¬í•™"],
    '200 ì¢…êµ': ["ì¢…êµ", "ê¸°ë…êµ", "ë¶ˆêµ", "ì²œì£¼êµ", "ì‹ í™”", "ì‹ ì•™", "ì¢…êµí•™"],
    '300 ì‚¬íšŒê³¼í•™': ["ì‚¬íšŒ", "ì •ì¹˜", "ê²½ì œ", "ë²•ë¥ ", "í–‰ì •", "êµìœ¡", "ë³µì§€", "ì—¬ì„±", "ë…¸ì¸", "ìœ¡ì•„", "ì•„ë™ë³µì§€", "ì‚¬íšŒë¬¸ì œ", "ë…¸ë™", "í™˜ê²½ë¬¸ì œ", "ì¸ê¶Œ"],
    '400 ìì—°ê³¼í•™': ["ìˆ˜í•™", "ë¬¼ë¦¬", "í™”í•™", "ìƒë¬¼", "ì§€êµ¬ê³¼í•™", "ê³¼í•™", "ì²œë¬¸", "ê¸°í›„", "ì˜í•™", "ìƒëª…ê³¼í•™"],
    '500 ê¸°ìˆ ê³¼í•™': ["ê±´ê°•", "ì˜ë£Œ", "ìš”ë¦¬", "ê°„í˜¸", "ê³µí•™", "ì»´í“¨í„°", "AI", "IT", "ë†ì—…", "ì¶•ì‚°", "ì‚°ì—…", "ê¸°ìˆ ", "ë¯¸ìš©"],
    '600 ì˜ˆìˆ ': ["ë¯¸ìˆ ", "ìŒì•…", "ë¬´ìš©", "ì‚¬ì§„", "ì˜í™”", "ì—°ê·¹", "ë””ìì¸", "ê³µì˜ˆ", "ì˜ˆìˆ ", "ë¬¸í™”ì˜ˆìˆ "],
    '700 ì–¸ì–´': ["ì–¸ì–´", "êµ­ì–´", "ì˜ì–´", "ì¼ë³¸ì–´", "ì¤‘êµ­ì–´", "ì™¸êµ­ì–´", "í•œì", "ë¬¸ë²•"],
    '800 ë¬¸í•™': ["ì†Œì„¤", "ì‹œ", "ìˆ˜í•„", "ì—ì„¸ì´", "í¬ê³¡", "ë¬¸í•™", "ë™í™”", "ì›¹íˆ°", "íŒíƒ€ì§€", "ë¬¸ì˜ˆ"],
    '900 ì—­ì‚¬Â·ì§€ë¦¬': ["ì—­ì‚¬", "ì§€ë¦¬", "í•œêµ­ì‚¬", "ì„¸ê³„ì‚¬", "ì—¬í–‰", "ë¬¸í™”ìœ ì‚°", "ê´€ê´‘"],
}

# ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„ ì˜µì…˜
SEGMENT_OPTIONS = [
    {"label": "SQ1. ì„±ë³„", "key": "SQ1"},
    {"label": "SQ2. ì—°ë ¹", "key": "SQ2"},
    {"label": "SQ3. ê±°ì£¼ì§€", "key": "SQ3"},
    {"label": "SQ4. ì£¼ ì´ìš© ë„ì„œê´€", "key": "SQ4"},
    {"label": "SQ5. ì£¼ë¡œ ì´ìš© ì„œë¹„ìŠ¤", "key": "SQ5"},
    {"label": "DQ1. ì›”í‰ê·  ì´ìš© ë¹ˆë„", "key": "DQ1"},
    {"label": "DQ2. ì´ìš©ê¸°ê°„", "key": "DQ2"},
    {"label": "DQ4. (1ìˆœìœ„)ì´ìš©ëª©ì ", "key": "DQ4"},
]

# -----------------------------------------------------------------------------
# 1. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (Utility Functions)
# -----------------------------------------------------------------------------

def wrap_label(label: str, width: int = 10) -> str:
    """ê¸´ ë ˆì´ë¸”ì„ ì§€ì •ëœ ë„ˆë¹„ë¡œ ì¤„ë°”ê¿ˆí•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return '<br>'.join([label[i:i+width] for i in range(0, len(label), width)])

def remove_parentheses(text: str) -> str:
    """ë¬¸ìì—´ì—ì„œ ê´„í˜¸ì™€ ê·¸ ì•ˆì˜ ë‚´ìš©ì„ ì œê±°í•©ë‹ˆë‹¤."""
    return re.sub(r'\(.*?\)', '', text).strip()

def get_qualitative_colors(n: int) -> List[str]:
    """nê°œì˜ ì§ˆì  ìƒ‰ìƒ íŒ”ë ˆíŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return [color for _, color in zip(range(n), cycle(DEFAULT_PALETTE))]

def escape_tildes(text: str) -> str:
    """ë§ˆí¬ë‹¤ìš´ì—ì„œ '~'ê°€ ì·¨ì†Œì„ ìœ¼ë¡œ í•´ì„ë˜ëŠ” ê²ƒì„ ë°©ì§€í•©ë‹ˆë‹¤."""
    return text.replace("~", "ï½")

def render_insight_card(title: str, content: str, key: str):
    """ì¸ì‚¬ì´íŠ¸ë¥¼ ë³´ê¸° ì¢‹ì€ ì¹´ë“œ í˜•íƒœë¡œ ë Œë”ë§í•©ë‹ˆë‹¤."""
    if not content:
        content = "(ë¶„ì„ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.)"
    
    content_html = escape_tildes(content).replace("\n", "<br>")
    
    html = f"""
    <div style="
        border: 1px solid #e2e8f0;
        border-radius: 12px;
        padding: 20px;
        margin-bottom: 16px;
        background: #f8f9fa;
        box-shadow: 0 4px 12px rgba(0,0,0,0.05);
        font-family: 'Pretendard', sans-serif;
    ">
        <h4 style="margin:0 0 12px 0; font-size:1.1rem; color:#333; border-bottom: 2px solid #dee2e6; padding-bottom: 8px;">{title}</h4>
        <div style="font-size:0.95em; line-height:1.6em; color:#555;">{content_html}</div>
    </div>
    """
    components.html(html, height=min(800, 100 + content.count('\n') * 25), scrolling=True)


# -----------------------------------------------------------------------------
# 2. ë°ì´í„° ì²˜ë¦¬ ë° ê³„ì‚° í•¨ìˆ˜ (Data Processing & Computation)
# -----------------------------------------------------------------------------

@st.cache_data
def load_data(uploaded_file) -> Optional[pd.DataFrame]:
    """ì—…ë¡œë“œëœ ì—‘ì…€ íŒŒì¼ì„ ì½ì–´ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        df = pd.read_excel(uploaded_file)
        return df
    except Exception as e:
        logging.error(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
        st.error(f"ì—‘ì…€ íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return None

def scale_likert(series: pd.Series) -> pd.Series:
    """7ì  ì²™ë„ ì ìˆ˜ë¥¼ 0-100ì  ì²™ë„ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    # 7ì  ì²™ë„ì´ë¯€ë¡œ (ì ìˆ˜-1) / 6 ì„ í•˜ì—¬ 0~1 ì‚¬ì´ë¡œ ì •ê·œí™” í›„ 100ì„ ê³±í•¨
    return 100 * (pd.to_numeric(series, errors='coerce') - 1) / 6

@st.cache_data(show_spinner="ì¤‘ë¶„ë¥˜ ì ìˆ˜ë¥¼ ê³„ì‚° ì¤‘ì…ë‹ˆë‹¤...")
def compute_midcategory_scores(_df: pd.DataFrame) -> pd.Series:
    """ë°ì´í„°í”„ë ˆì„ì—ì„œ ì¤‘ë¶„ë¥˜ë³„ í‰ê·  ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    results = {}
    for mid, predicate in MIDDLE_CATEGORY_MAPPING.items():
        cols = [c for c in _df.columns if predicate(c)]
        if not cols:
            continue
        
        # ê° ë¬¸í•­ì„ 100ì  ì²™ë„ë¡œ ë³€í™˜
        scaled = _df[cols].apply(scale_likert)
        # ëª¨ë“  ë¬¸í•­ì˜ í‰ê· ì„ ê³„ì‚°í•˜ì—¬ ì¤‘ë¶„ë¥˜ ì ìˆ˜ë¡œ ì‚¼ìŒ
        mid_mean = scaled.mean(axis=0, skipna=True).mean()
        if not pd.isna(mid_mean):
            results[mid] = mid_mean
            
    return pd.Series(results)

@st.cache_data(show_spinner="ì„¸ë¶€ ë¬¸í•­ ì ìˆ˜ë¥¼ ê³„ì‚° ì¤‘ì…ë‹ˆë‹¤...")
def compute_within_category_item_scores(_df: pd.DataFrame) -> Dict[str, pd.Series]:
    """ì¤‘ë¶„ë¥˜ ë‚´ ê° ì„¸ë¶€ ë¬¸í•­ë³„ í‰ê·  ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    item_scores = {}
    for mid, predicate in MIDDLE_CATEGORY_MAPPING.items():
        cols = [c for c in _df.columns if predicate(c)]
        if not cols:
            continue
        
        scaled = _df[cols].apply(scale_likert)
        item_means = scaled.mean(axis=0, skipna=True)
        item_scores[mid] = item_means
        
    return item_scores

def apply_filters(df: pd.DataFrame, filters: List[Dict[str, Any]]) -> pd.DataFrame:
    """ì§€ì •ëœ í•„í„° ëª©ë¡ì„ ë°ì´í„°í”„ë ˆì„ì— ì ìš©í•©ë‹ˆë‹¤."""
    dff = df.copy()
    for f in filters:
        col, op, val = f.get("col"), f.get("op"), f.get("value")
        if not all([col, op, val]) or col not in dff.columns:
            continue
        
        try:
            if op in ("==", "="):
                dff = dff[dff[col].astype(str) == str(val)]
            elif op == "in" and isinstance(val, list):
                dff = dff[dff[col].astype(str).isin(map(str, val))]
            elif op == "contains":
                dff = dff[dff[col].astype(str).str.contains(str(val), na=False)]
        except Exception as e:
            logging.warning(f"í•„í„° ì ìš© ì‹¤íŒ¨: {col} {op} {val}. ì˜¤ë¥˜: {e}")

    return dff

# -----------------------------------------------------------------------------
# 3. GPT-4 ì—°ë™ í•¨ìˆ˜ (OpenAI Integration)
# -----------------------------------------------------------------------------

def safe_chat_completion(**kwargs) -> Optional[str]:
    """ì•ˆì „í•˜ê²Œ OpenAI Chat Completion APIë¥¼ í˜¸ì¶œí•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        response = client.chat.completions.create(**kwargs)
        return response.choices[0].message.content.strip()
    except Exception as e:
        logging.error(f"OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        st.warning(f"AI ëª¨ë¸ í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ({e})")
        return None

def parse_nl_query_to_spec(question: str) -> Dict[str, Any]:
    """ìì—°ì–´ ì§ˆì˜ë¥¼ ë¶„ì„í•˜ì—¬ JSON í˜•íƒœì˜ ë¶„ì„ ëª…ì„¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    system_prompt = """
    ë‹¹ì‹ ì€ ì„¤ë¬¸ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ìì—°ì–´ ì§ˆë¬¸ì„ ì‹œê°í™” ë° ë¶„ì„ì„ ìœ„í•œ JSON ëª…ì„¸ë¡œ ë³€í™˜í•˜ì„¸ìš”.
    ì¶œë ¥ì€ ë°˜ë“œì‹œ JSON ê°ì²´ í•˜ë‚˜ë§Œ, ì½”ë“œ ë¸”ë¡ ì—†ì´ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤.
    ì•Œ ìˆ˜ ì—†ëŠ” ê°’ì€ nullì´ë‚˜ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬í•˜ì„¸ìš”.

    JSON í•„ë“œ ì„¤ëª…:
    - chart: ì¶”ì²œ ì°¨íŠ¸ ìœ í˜• ('bar', 'heatmap', 'radar', 'grouped_bar', 'delta_bar', 'none' ë“±)
    - x: ë¶„ì„ì˜ ì£¼ìš” ì¶•ì´ ë  ì»¬ëŸ¼ëª… ë˜ëŠ” 'ì¤‘ë¶„ë¥˜'
    - y: yì¶•ì— í•´ë‹¹í•˜ëŠ” ì»¬ëŸ¼ëª… (ì£¼ë¡œ xì™€ í•¨ê»˜ ì‚¬ìš©)
    - groupby: ë¹„êµ ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©í•  ê·¸ë£¹í™” ì»¬ëŸ¼ëª…
    - filters: ë°ì´í„° í•„í„°ë§ ì¡°ê±´ ë°°ì—´ (e.g., [{"col": "SQ1. ì„±ë³„", "op": "==", "value": "ì—¬"}])
    - focus: ì‚¬ìš©ìì˜ í•µì‹¬ ì§ˆë¬¸ ì˜ë„ë¥¼ ìš”ì•½í•œ ë¬¸ì¥

    ì˜ˆì‹œ:
    1. ì§ˆë¬¸: "í˜¼ì ì´ìš©í•˜ëŠ” 30ëŒ€ ì—¬ì„±ë“¤ì˜ ì£¼ ì´ìš© ë„ì„œê´€ë³„ ë§Œì¡±ë„ ê°•ì ê³¼ ì•½ì ì„ ë¹„êµí•´ì¤˜."
       ê²°ê³¼: {
            "chart": "radar",
            "x": "ì¤‘ë¶„ë¥˜",
            "groupby": "SQ4. ì£¼ ì´ìš© ë„ì„œê´€",
            "filters": [
                {"col": "ì´ìš©í˜•íƒœ", "op": "contains", "value": "í˜¼ì"},
                {"col": "SQ1. ì„±ë³„", "op": "==", "value": "ì—¬"},
                {"col": "SQ2_GROUP", "op": "in", "value": ["30~34ì„¸", "35~39ì„¸"]}
            ],
            "focus": "30ëŒ€ ì—¬ì„± ë‹¨ë… ì´ìš©ìì˜ ì£¼ ì´ìš© ë„ì„œê´€ë³„ ë§Œì¡±ë„ í”„ë¡œíŒŒì¼ ë¹„êµ"
          }
    2. ì§ˆë¬¸: "ì „ì²´ í‰ê· ê³¼ ë¹„êµí•´ì„œ ì–´ë–¤ ì¤‘ë¶„ë¥˜ê°€ ê°•ì ì¸ì§€ ë³´ì—¬ì¤˜."
       ê²°ê³¼: {"chart": "radar", "x": "ì¤‘ë¶„ë¥˜", "groupby": null, "filters": [], "focus": "ì „ì²´ í‰ê·  ëŒ€ë¹„ ì¤‘ë¶„ë¥˜ë³„ ê°•ì /ì•½ì  ë¶„ì„"}
    """
    content = safe_chat_completion(
        model="gpt-4-turbo",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": question}
        ],
        temperature=0.1,
        max_tokens=500,
        response_format={"type": "json_object"}
    )
    
    if content:
        try:
            return json.loads(content)
        except json.JSONDecodeError:
            logging.error("GPTë¡œë¶€í„° ìœ íš¨í•˜ì§€ ì•Šì€ JSON ì‘ë‹µì„ ë°›ì•˜ìŠµë‹ˆë‹¤.")
    
    # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
    return {"chart": None, "x": None, "y": None, "groupby": None, "filters": [], "focus": question}


def generate_insight_from_data(prompt: str) -> str:
    """ì£¼ì–´ì§„ í”„ë¡¬í”„íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ GPTë¥¼ í˜¸ì¶œí•˜ì—¬ ë°ì´í„° ë¶„ì„ ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    system_prompt = "ë‹¹ì‹ ì€ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì´ì ì „ëµ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•µì‹¬ì ì¸ ê´€ì°°, ëª…í™•í•œ ê²°ë¡ , ê·¸ë¦¬ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì œì•ˆì„ ë‹´ì€ ë¹„ì¦ˆë‹ˆìŠ¤ ë³´ê³ ì„œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤. ê°„ê²°í•˜ê³  ëª…í™•í•œ ì–´ì¡°ë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”."
    
    content = safe_chat_completion(
        model="gpt-4-turbo",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": prompt}
        ],
        temperature=0.3,
        max_tokens=1200
    )
    return escape_tildes(content) if content else "ì¸ì‚¬ì´íŠ¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."

# -----------------------------------------------------------------------------
# 4. ì‹œê°í™” í•¨ìˆ˜ (Plotting Functions)
# -----------------------------------------------------------------------------

def plot_categorical_bar(df: pd.DataFrame, col: str, title: str) -> Tuple[go.Figure, pd.DataFrame]:
    """ë²”ì£¼í˜• ë°ì´í„°ì— ëŒ€í•œ ë§‰ëŒ€ ì°¨íŠ¸ì™€ ìš”ì•½ í…Œì´ë¸”ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    counts = df[col].value_counts()
    percent = (counts / counts.sum() * 100).round(1)
    
    fig = px.bar(
        x=counts.index, 
        y=counts.values,
        text=counts.values,
        title=title,
        labels={'x': col, 'y': 'ì‘ë‹µ ìˆ˜'}
    )
    fig.update_traces(textposition='outside')
    fig.update_layout(height=400, showlegend=False)
    
    table = pd.DataFrame({'ì‘ë‹µ ìˆ˜': counts, 'ë¹„ìœ¨ (%)': percent}).T
    return fig, table

def plot_likert_stacked_bar(df: pd.DataFrame, col: str) -> Tuple[go.Figure, pd.DataFrame]:
    """ë¦¬ì»¤íŠ¸ ì²™ë„ ë°ì´í„°ì— ëŒ€í•œ ìŠ¤íƒí˜• ë§‰ëŒ€ ì°¨íŠ¸ì™€ ìš”ì•½ í…Œì´ë¸”ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    order = sorted(df[col].dropna().unique())
    counts = df[col].value_counts().reindex(order, fill_value=0)
    percent = (counts / counts.sum() * 100).round(1)
    
    fig = go.Figure()
    for val in order:
        fig.add_trace(go.Bar(
            x=[percent[val]], 
            y=[remove_parentheses(col)], 
            orientation='h', 
            name=f"{val}ì ",
            marker_color=LIKERT_COLORS.get(val, 'grey'),
            text=f"{percent[val]}%",
            textposition='inside',
            insidetextanchor='middle'
        ))
        
    fig.update_layout(
        barmode='stack',
        title=col,
        xaxis_title="ë¹„ìœ¨ (%)",
        yaxis=dict(showticklabels=False),
        height=180,
        margin=dict(t=40, b=20, l=10, r=10),
        legend=dict(orientation="h", yanchor="bottom", y=-0.3, xanchor="center", x=0.5)
    )
    
    table = pd.DataFrame([counts, percent], index=["ì‘ë‹µ ìˆ˜", "ë¹„ìœ¨ (%)"], columns=[f"{v}ì " for v in order])
    return fig, table

def plot_midcategory_radar(df: pd.DataFrame, title: str = "ì¤‘ë¶„ë¥˜ë³„ ë§Œì¡±ë„ ìˆ˜ì¤€") -> Optional[go.Figure]:
    """ì¤‘ë¶„ë¥˜ë³„ ë§Œì¡±ë„ ì ìˆ˜ë¥¼ ë ˆì´ë” ì°¨íŠ¸ë¡œ ì‹œê°í™”í•©ë‹ˆë‹¤."""
    mid_scores = compute_midcategory_scores(df)
    if mid_scores.empty:
        return None

    categories = list(mid_scores.index)
    values = mid_scores.values.tolist()
    
    fig = go.Figure()
    fig.add_trace(go.Scatterpolar(
        r=values + [values[0]],
        theta=categories + [categories[0]],
        fill='toself',
        name='ë§Œì¡±ë„',
        hovertemplate="%{theta}: %{r:.1f}<extra></extra>"
    ))
    
    fig.update_layout(
        polar=dict(radialaxis=dict(visible=True, range=[0, 100])),
        title=title,
        height=450,
        margin=dict(t=80, b=40)
    )
    return fig

def plot_grouped_bar(df: pd.DataFrame, x_col: str, y_col: str, group_col: str) -> Optional[go.Figure]:
    """ê·¸ë£¹í™”ëœ ë§‰ëŒ€ ì°¨íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    if not all(c in df.columns for c in [x_col, y_col, group_col]):
        return None

    fig = px.bar(
        df,
        x=x_col,
        y=y_col,
        color=group_col,
        barmode="group",
        text_auto=".2s",
        title=f"{x_col} ë° {group_col}ì— ë”°ë¥¸ {y_col} ë¹„êµ"
    )
    fig.update_layout(height=450)
    return fig

def plot_heatmap(df: pd.DataFrame, title: str) -> Optional[go.Figure]:
    """ë°ì´í„°í”„ë ˆì„ì„ íˆíŠ¸ë§µìœ¼ë¡œ ì‹œê°í™”í•©ë‹ˆë‹¤."""
    if df.empty:
        return None
        
    fig = px.imshow(
        df,
        text_auto=True,
        aspect="auto",
        color_continuous_scale="Blues",
        title=title
    )
    fig.update_layout(height=max(400, len(df.index) * 30))
    return fig


# -----------------------------------------------------------------------------
# 5. Streamlit í˜ì´ì§€ ë Œë”ë§ í•¨ìˆ˜ (UI Rendering)
# -----------------------------------------------------------------------------

def render_basic_analysis_page(df: pd.DataFrame):
    """'ê¸°ë³¸ ë¶„ì„' í˜ì´ì§€ë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤."""
    st.header("ğŸ“Š ê¸°ë³¸ ë¬¸í•­ ë¶„ì„")
    
    # ì¸êµ¬í†µê³„ ë° ê¸°ë³¸ ì§ˆë¬¸
    sq_cols = [c for c in df.columns if c.startswith("SQ") or c.startswith("BQ")]
    likert_cols = [c for c in df.columns if re.match(r"Q[1-9][\.-]", str(c))]
    
    with st.expander("ğŸ‘¤ ì‘ë‹µì ì •ë³´ (SQ, BQ ë¬¸í•­)", expanded=True):
        for col in sq_cols:
            fig, table = plot_categorical_bar(df, col, col)
            st.plotly_chart(fig, use_container_width=True)
            st.dataframe(table)
            st.divider()

    with st.expander("ğŸ“ˆ 7ì  ì²™ë„ ë§Œì¡±ë„ ë¬¸í•­ (Q1 ~ Q8)", expanded=True):
        for col in likert_cols:
            fig, table = plot_likert_stacked_bar(df, col)
            st.plotly_chart(fig, use_container_width=True)
            st.dataframe(table)
            st.divider()

def render_advanced_analysis_page(df: pd.DataFrame):
    """'ì‹¬í™” ë¶„ì„' í˜ì´ì§€ë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤."""
    st.header("ğŸ”¬ ì‹¬í™” ë¶„ì„")

    tabs = st.tabs(["ì „ì²´ ì¤‘ë¶„ë¥˜ ë¶„ì„", "ì„¸ë¶€ í•­ëª©ë³„ í¸ì°¨ ë¶„ì„", "ì´ìš©ì ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„"])

    with tabs[0]:
        st.subheader("ì¤‘ë¶„ë¥˜ë³„ ì „ì²´ ë§Œì¡±ë„")
        fig = plot_midcategory_radar(df)
        if fig:
            st.plotly_chart(fig, use_container_width=True)
            scores = compute_midcategory_scores(df).rename("í‰ê·  ì ìˆ˜").round(2)
            st.dataframe(scores)
        else:
            st.warning("ì¤‘ë¶„ë¥˜ ì ìˆ˜ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    with tabs[1]:
        st.subheader("ì¤‘ë¶„ë¥˜ ë‚´ ì„¸ë¶€ ë¬¸í•­ë³„ ë§Œì¡±ë„ í¸ì°¨")
        item_scores_by_mid = compute_within_category_item_scores(df)
        mid_scores = compute_midcategory_scores(df)
        
        for mid, item_scores in item_scores_by_mid.items():
            with st.expander(f"**{mid}** ë‚´ ë¬¸í•­ë³„ ë¹„êµ", expanded=False):
                mid_mean = mid_scores.get(mid)
                if item_scores.empty or mid_mean is None:
                    st.write("ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    continue

                plot_df = item_scores.rename("ì ìˆ˜").to_frame()
                plot_df['í¸ì°¨'] = plot_df['ì ìˆ˜'] - mid_mean
                
                fig = px.bar(
                    plot_df, 
                    x='í¸ì°¨', 
                    y=plot_df.index, 
                    orientation='h',
                    title=f"'{mid}' ë‚´ ë¬¸í•­ë³„ í‰ê·  ëŒ€ë¹„ í¸ì°¨",
                    text=plot_df['ì ìˆ˜'].round(1)
                )
                fig.add_vline(x=0, line_width=2, line_dash="dash", line_color="red")
                fig.update_layout(height=max(300, len(plot_df) * 40), yaxis={'categoryorder':'total ascending'})
                st.plotly_chart(fig, use_container_width=True)
                st.dataframe(plot_df.round(2))

    with tabs[2]:
        page_segment_analysis(df)


def page_segment_analysis(df: pd.DataFrame):
    """ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„ UI ë° ë¡œì§ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    st.subheader("ğŸ‘¥ ì´ìš©ì ì„¸ê·¸ë¨¼íŠ¸ ì¡°í•© ë¶„ì„")
    st.markdown("ì¸êµ¬í†µê³„ ë° ì´ìš©í–‰íƒœ ë³€ìˆ˜ë¥¼ ì¡°í•©í•˜ì—¬, íŠ¹ì • ì´ìš©ì ê·¸ë£¹ì˜ ì¤‘ë¶„ë¥˜ë³„ ë§Œì¡±ë„ í”„ë¡œíŒŒì¼ì„ ì‹¬ì¸µ ë¶„ì„í•©ë‹ˆë‹¤.")

    sel_labels = st.multiselect(
        "ë¶„ì„ì— ì‚¬ìš©í•  ì„¸ê·¸ë¨¼íŠ¸ ë³€ìˆ˜ ì„ íƒ (ìµœëŒ€ 3ê°œ)",
        [o['label'] for o in SEGMENT_OPTIONS],
        default=[SEGMENT_OPTIONS[0]['label'], SEGMENT_OPTIONS[1]['label']],
        max_selections=3
    )
    
    if len(sel_labels) < 1:
        st.info("ë¶„ì„í•  ì„¸ê·¸ë¨¼íŠ¸ ë³€ìˆ˜ë¥¼ 1ê°œ ì´ìƒ ì„ íƒí•´ì£¼ì„¸ìš”.")
        return

    selected_keys = [o['key'] for o in SEGMENT_OPTIONS if o['label'] in sel_labels]
    
    # íŒŒìƒ ë³€ìˆ˜ ì¶”ê°€ (ì˜ˆ: ì—°ë ¹ëŒ€ ê·¸ë£¹)
    # ì´ ë¶€ë¶„ì€ ì‹¤ì œ ë°ì´í„° ì»¬ëŸ¼ëª…ì— ë§ê²Œ ì»¤ìŠ¤í„°ë§ˆì´ì§• í•„ìš”
    if "SQ2" in selected_keys and "SQ2_GROUP" not in df.columns:
        # ì˜ˆì‹œ: 'SQ2. ì—°ë ¹' ì»¬ëŸ¼ì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œí•˜ì—¬ ì—°ë ¹ëŒ€ ê·¸ë£¹ ìƒì„±
        age_series = pd.to_numeric(df['SQ2. ì—°ë ¹'].astype(str).str.extract(r'(\d+)')[0], errors='coerce')
        bins = [0, 19, 29, 39, 49, 59, 69, 120]
        labels = ['10ëŒ€ ì´í•˜', '20ëŒ€', '30ëŒ€', '40ëŒ€', '50ëŒ€', '60ëŒ€', '70ëŒ€ ì´ìƒ']
        df['SQ2_GROUP'] = pd.cut(age_series, bins=bins, labels=labels, right=True)

    segment_cols = []
    col_map = {"SQ2": "SQ2_GROUP"} # ì›ë³¸ í‚¤ë¥¼ íŒŒìƒë³€ìˆ˜ ì»¬ëŸ¼ìœ¼ë¡œ ë§¤í•‘
    for key in selected_keys:
        # ì‹¤ì œ ë°ì´í„°ì— ìˆëŠ” ì»¬ëŸ¼ëª…ì„ ì°¾ì•„ ì¶”ê°€
        mapped_key = col_map.get(key, key)
        cols = [c for c in df.columns if mapped_key in c]
        if cols:
            segment_cols.append(cols[0])

    if not segment_cols:
        st.warning("ì„ íƒí•œ ë³€ìˆ˜ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„° ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ê·¸ë£¹ë³„ ì¤‘ë¶„ë¥˜ ì ìˆ˜ ê³„ì‚°
    grouped = df.dropna(subset=segment_cols).groupby(segment_cols)
    
    results = []
    for name, group_df in grouped:
        if len(group_df) < 5:  # ìµœì†Œ ì‘ë‹µì ìˆ˜ í•„í„°ë§
            continue
        scores = compute_midcategory_scores(group_df)
        if scores.empty:
            continue
        
        # ê·¸ë£¹ ì´ë¦„ì´ íŠœí”Œì¼ ê²½ìš° ë¬¸ìì—´ë¡œ ë³€í™˜
        group_name = " | ".join(map(str, name)) if isinstance(name, tuple) else str(name)
        
        result_row = scores.to_dict()
        result_row['ì„¸ê·¸ë¨¼íŠ¸'] = group_name
        result_row['ì‘ë‹µììˆ˜'] = len(group_df)
        results.append(result_row)

    if not results:
        st.warning("ë¶„ì„ ê°€ëŠ¥í•œ ì„¸ê·¸ë¨¼íŠ¸ ê·¸ë£¹ì´ ì—†ìŠµë‹ˆë‹¤ (ì‘ë‹µì ìˆ˜ 5ëª… ì´ìƒ).")
        return

    result_df = pd.DataFrame(results).set_index('ì„¸ê·¸ë¨¼íŠ¸')
    
    # ì‹œê°í™”
    st.markdown("#### ì„¸ê·¸ë¨¼íŠ¸ë³„ ë§Œì¡±ë„ íˆíŠ¸ë§µ")
    heatmap_df = result_df.drop(columns=['ì‘ë‹µììˆ˜'])
    fig = plot_heatmap(heatmap_df, "ì„¸ê·¸ë¨¼íŠ¸ë³„ ì¤‘ë¶„ë¥˜ ë§Œì¡±ë„ í‰ê· ")
    if fig:
        st.plotly_chart(fig, use_container_width=True)

    # GPT ì¸ì‚¬ì´íŠ¸
    st.markdown("#### AI ê¸°ë°˜ ë¶„ì„ ë¦¬í¬íŠ¸")
    prompt = f"""
    ë‹¤ìŒì€ ë„ì„œê´€ ì´ìš©ì ì„¸ê·¸ë¨¼íŠ¸ë³„ ì¤‘ë¶„ë¥˜ ë§Œì¡±ë„ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.
    ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¹„ì¦ˆë‹ˆìŠ¤ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

    ë°ì´í„° (ì¸ë±ìŠ¤: ì„¸ê·¸ë¨¼íŠ¸, ì»¬ëŸ¼: ì¤‘ë¶„ë¥˜, ê°’: ë§Œì¡±ë„ ì ìˆ˜):
    {heatmap_df.to_markdown()}

    ë³´ê³ ì„œì— í¬í•¨í•  ë‚´ìš©:
    1.  **í•µì‹¬ ìš”ì•½ (Overall Summary):** ê°€ì¥ ë‘ë“œëŸ¬ì§€ëŠ” íŒ¨í„´ì´ë‚˜ ì¸ì‚¬ì´íŠ¸ë¥¼ 2-3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.
    2.  **ì£¼ìš” ê°•ì  ê·¸ë£¹ (High-Performing Segments):** ì „ë°˜ì ìœ¼ë¡œ ë§Œì¡±ë„ê°€ ë†’ì€ ì„¸ê·¸ë¨¼íŠ¸ ê·¸ë£¹ë“¤ì„ ì‹ë³„í•˜ê³ , ê·¸ë“¤ì˜ ê³µí†µì ì¸ ê°•ì  ì˜ì—­ì„ ë¶„ì„í•©ë‹ˆë‹¤.
    3.  **ê°œì„  í•„ìš” ê·¸ë£¹ (Segments Needing Attention):** ë§Œì¡±ë„ê°€ ë‚®ì€ ê·¸ë£¹ë“¤ì„ ì‹ë³„í•˜ê³ , íŠ¹íˆ ì–´ë–¤ ì¤‘ë¶„ë¥˜ì—ì„œ ê°œì„ ì´ ì‹œê¸‰í•œì§€ ì„¤ëª…í•©ë‹ˆë‹¤.
    4.  **ì „ëµì  ì œì–¸ (Strategic Recommendations):** ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ë„ì„œê´€ì´ ìš°ì„ ì ìœ¼ë¡œ ê³ ë ¤í•´ì•¼ í•  2-3ê°€ì§€ ì „ëµì  ë°©í–¥ì„ êµ¬ì²´ì ìœ¼ë¡œ ì œì•ˆí•©ë‹ˆë‹¤. (ì˜ˆ: '30ëŒ€ ì—¬ì„± ê·¸ë£¹ì˜ 'ì†Œí†µ ë° ì •ì±… í™œìš©' ë§Œì¡±ë„ ê°œì„ ì„ ìœ„í•œ í”„ë¡œê·¸ë¨ ê¸°íš')
    """
    insight = generate_insight_from_data(prompt)
    render_insight_card("ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„ AI ë¦¬í¬íŠ¸", insight, "segment-insight")


def render_nl_query_page(df: pd.DataFrame):
    """'ìì—°ì–´ ì§ˆì˜' í˜ì´ì§€ë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤."""
    st.header("ğŸ’¬ ìì—°ì–´ ì§ˆë¬¸ ê¸°ë°˜ ìë™ ë¶„ì„")
    st.markdown("ê¶ê¸ˆí•œ ì ì„ ììœ ë¡­ê²Œ ì§ˆë¬¸í•˜ë©´, AIê°€ ì§ˆë¬¸ì„ í•´ì„í•˜ì—¬ ìë™ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì‹œê°í™”í•©ë‹ˆë‹¤.")
    st.info("ì˜ˆì‹œ: '20ëŒ€ ë‚¨ì„±ì˜ ê³µê°„ ë§Œì¡±ë„ëŠ” ì–´ë–¤ê°€ìš”?' ë˜ëŠ” 'ì£¼ ì´ìš© ë„ì„œê´€ë³„ë¡œ ë§Œì¡±ë„ ì°¨ì´ë¥¼ ë¹„êµí•´ì¤˜.'")

    question = st.text_input("ë¶„ì„í•˜ê³  ì‹¶ì€ ë‚´ìš©ì„ ì§ˆë¬¸í•´ì£¼ì„¸ìš”:", key="nl_question")

    if question:
        with st.spinner("AIê°€ ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            spec = parse_nl_query_to_spec(question)
        
        st.markdown("#### ğŸ¤– AI ë¶„ì„ ì„¤ê³„")
        with st.expander("AIê°€ ì´í•´í•œ ë¶„ì„ ëª…ì„¸ ë³´ê¸°"):
            st.json(spec)

        # 1. í•„í„° ì ìš©
        df_filtered = apply_filters(df, spec.get("filters", []))
        st.write(f"ì´ {len(df)}ê°œ ì‘ë‹µ ì¤‘, í•„í„° ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” **{len(df_filtered)}ê°œ**ì˜ ë°ì´í„°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")

        if df_filtered.empty:
            st.warning("ì§ˆë¬¸ ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # 2. ë¶„ì„ ë° ì‹œê°í™”
        chart_type = spec.get("chart")
        x_col = spec.get("x")
        y_col = spec.get("y")
        group_col = spec.get("groupby")

        # ë¶„ì„ ë¡œì§ì„ ì—¬ê¸°ì— êµ¬í˜„
        # ì˜ˆ: xê°€ 'ì¤‘ë¶„ë¥˜'ì´ë©´ ë ˆì´ë” ì°¨íŠ¸, groupbyê°€ ìˆìœ¼ë©´ ê·¸ë£¹ë°” ì°¨íŠ¸ ë“±
        if x_col == 'ì¤‘ë¶„ë¥˜':
            fig = plot_midcategory_radar(df_filtered, title=f"ë¶„ì„ ê²°ê³¼: {spec.get('focus')}")
            if fig:
                st.plotly_chart(fig, use_container_width=True)
        elif x_col and y_col and group_col:
             # ë°ì´í„° ì§‘ê³„
            agg_df = df_filtered.groupby([x_col, group_col])[y_col].mean().reset_index()
            fig = plot_grouped_bar(agg_df, x_col, y_col, group_col)
            if fig:
                st.plotly_chart(fig, use_container_width=True)
        elif x_col:
            fig, _ = plot_categorical_bar(df_filtered, x_col, title=f"ë¶„ì„ ê²°ê³¼: {spec.get('focus')}")
            st.plotly_chart(fig, use_container_width=True)
        else:
             st.info("ì§ˆë¬¸ì— ë§ëŠ” ì‹œê°í™”ë¥¼ ìƒì„±í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ìœ¼ë¡œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”.")

        # 3. GPT ê¸°ë°˜ ì„¤ëª… ìƒì„±
        with st.spinner("AIê°€ ë¶„ì„ ê²°ê³¼ë¥¼ í•´ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„± ì‹œ, ë¶„ì„ì— ì‚¬ìš©ëœ ë°ì´í„° ìš”ì•½ ì •ë³´ë¥¼ í¬í•¨í•˜ë©´ ë” ì¢‹ì€ ê²°ê³¼ ìƒì„± ê°€ëŠ¥
            prompt = f"""
            ì‚¬ìš©ìì˜ ì§ˆë¬¸ "{question}"ì— ëŒ€í•´ ë‹¤ìŒê³¼ ê°™ì€ ë¶„ì„ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.
            - ë¶„ì„ ëª…ì„¸: {json.dumps(spec, ensure_ascii=False)}
            - í•„í„°ë§ëœ ë°ì´í„° ìˆ˜: {len(df_filtered)}

            ì´ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ í•µì‹¬ ë‚´ìš©ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.
            """
            explanation = generate_insight_from_data(prompt)
            render_insight_card("AI ë¶„ì„ ê²°ê³¼ ìš”ì•½", explanation, "nl-explanation")


# -----------------------------------------------------------------------------
# 6. ë©”ì¸ ì‹¤í–‰ ë¡œì§ (Main Execution Logic)
# -----------------------------------------------------------------------------

def main():
    """ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ë©”ì¸ ë¡œì§ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    st.set_page_config(page_title="ë„ì„œê´€ ì„¤ë¬¸ ë¶„ì„ ëŒ€ì‹œë³´ë“œ", layout="wide")
    st.title("ğŸ“š ê³µê³µë„ì„œê´€ ì„¤ë¬¸ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
    st.markdown("---")

    # íŒŒì¼ ì—…ë¡œë“œ
    uploaded_file = st.sidebar.file_uploader("ğŸ“‚ ì—‘ì…€(.xlsx) íŒŒì¼ ì—…ë¡œë“œ", type=["xlsx"])
    
    if uploaded_file is None:
        st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ ë¶„ì„í•  ì„¤ë¬¸ ë°ì´í„° ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        st.stop()

    df = load_data(uploaded_file)
    if df is None:
        st.stop()

    # ë¶„ì„ ëª¨ë“œ ì„ íƒ
    st.sidebar.title("ë¶„ì„ ë©”ë‰´")
    mode = st.sidebar.radio(
        "ì›í•˜ëŠ” ë¶„ì„ ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”:",
        ["ê¸°ë³¸ ë¶„ì„", "ì‹¬í™” ë¶„ì„", "ìì—°ì–´ ì§ˆì˜(AI)"],
        captions=["ì „ì²´ ë¬¸í•­ë³„ ë¶„í¬ í™•ì¸", "ë³€ìˆ˜ ê°„ ê´€ê³„ ë° ê·¸ë£¹ ë¹„êµ", "AIì—ê²Œ ì§ˆë¬¸í•˜ì—¬ ìë™ ë¶„ì„"]
    )

    # ì„ íƒëœ ëª¨ë“œì— ë”°ë¼ í•´ë‹¹ í˜ì´ì§€ ë Œë”ë§
    if mode == "ê¸°ë³¸ ë¶„ì„":
        render_basic_analysis_page(df)
    elif mode == "ì‹¬í™” ë¶„ì„":
        render_advanced_analysis_page(df)
    elif mode == "ìì—°ì–´ ì§ˆì˜(AI)":
        render_nl_query_page(df)

if __name__ == "__main__":
    main()
