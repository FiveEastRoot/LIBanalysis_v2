import time
import numpy as np
import streamlit as st
import scipy.stats as stats
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
import re
import openai
import streamlit.components.v1 as components  # íŒŒì¼ ìƒë‹¨ì— ìœ„ì¹˜í•´ì•¼ í•¨
import json 
import math
import logging
from itertools import cycle



# ë¡œê¹… ì„¤ì • (í•„ìš”ì‹œ íŒŒì¼ë¡œë„ ë‚¨ê¸°ê²Œ ì¡°ì • ê°€ëŠ¥)
logging.basicConfig(level=logging.INFO)

openai.api_key = st.secrets["openai"]["api_key"]
client = openai.OpenAI(api_key=openai.api_key)

# ê¸°ë³¸ ìƒ‰ìƒ íŒ”ë ˆíŠ¸
DEFAULT_PALETTE = px.colors.qualitative.Plotly
COLOR_CYCLER = cycle(DEFAULT_PALETTE)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìœ í‹¸ë¦¬í‹°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def safe_chat_completion(*, model="gpt-4.1-nano", messages, temperature=0.2, max_tokens=300, retries=3, backoff_base=1.0):
    last_exc = None
    for attempt in range(1, retries + 1):
        try:
            resp = client.chat.completions.create(
                model=model,
                messages=messages,
                temperature=temperature,
                max_tokens=max_tokens
            )
            return resp
        except Exception as e:
            logging.warning(f"OpenAI call failed (attempt {attempt}): {e}")
            last_exc = e
            time.sleep(backoff_base * (2 ** (attempt - 1)))
    logging.error("OpenAI call failed after retries")
    raise last_exc

def interpret_midcategory_scores(df):
    scores = compute_midcategory_scores(df)
    if scores.empty:
        return "ì¤‘ë¶„ë¥˜ ì ìˆ˜ë¥¼ ê³„ì‚°í•  ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    overall = scores.mean()
    high = scores[scores >= overall + 5].index.tolist()
    low = scores[scores <= overall - 5].index.tolist()

    parts = []
    parts.append(f"ì „ì²´ ì¤‘ë¶„ë¥˜ í‰ê· ì€ {overall:.1f}ì ì…ë‹ˆë‹¤.")
    if high:
        parts.append(f"í‰ê· ë³´ë‹¤ ë†’ì€ ì¤‘ë¶„ë¥˜: {', '.join(high)}.")
    if low:
        parts.append(f"í‰ê· ë³´ë‹¤ ë‚®ì€ ì¤‘ë¶„ë¥˜: {', '.join(low)}.")
    if not high and not low:
        parts.append("ëª¨ë“  ì¤‘ë¶„ë¥˜ê°€ ì „ì²´ í‰ê·  ìˆ˜ì¤€ê³¼ ë¹„ìŠ·í•©ë‹ˆë‹¤.")
    return " ".join(parts)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì „ì²˜ë¦¬/ë§¤í•‘ ìœ í‹¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def remove_parentheses(text):
    return re.sub(r'\(.*?\)', '', text).strip()

def wrap_label(label, width=10):
    return '<br>'.join([label[i:i+width] for i in range(0, len(label), width)])

def get_qualitative_colors(n):
    palette = DEFAULT_PALETTE
    return [c for _, c in zip(range(n), cycle(palette))]

def wrap_label_fixed(label: str, width: int = 35) -> str:
    # í•œ ì¤„ì— ê³µë°± í¬í•¨ ì •í™•íˆ width ê¸€ìì”© ìë¥´ê³  <br>ë¡œ ì—°ê²°
    parts = [label[i:i+width] for i in range(0, len(label), width)]
    return "<br>".join(parts)

# ğŸ”§ KDC ë§¤í•‘ ë° ë¶„ì„ ìœ í‹¸
KDC_KEYWORD_MAP = {
    '000 ì´ë¥˜': ["ë°±ê³¼ì‚¬ì „", "ë„ì„œê´€", "ë…ì„œ", "ë¬¸í—Œì •ë³´", "ê¸°ë¡", "ì¶œíŒ", "ì„œì§€"],
    '100 ì² í•™': ["ì² í•™", "ëª…ìƒ", "ìœ¤ë¦¬", "ë…¼ë¦¬í•™", "ì‹¬ë¦¬í•™"],
    '200 ì¢…êµ': ["ì¢…êµ", "ê¸°ë…êµ", "ë¶ˆêµ", "ì²œì£¼êµ", "ì‹ í™”", "ì‹ ì•™", "ì¢…êµí•™"],
    '300 ì‚¬íšŒê³¼í•™': ["ì‚¬íšŒ", "ì •ì¹˜", "ê²½ì œ", "ë²•ë¥ ", "í–‰ì •", "êµìœ¡", "ë³µì§€", "ì—¬ì„±", "ë…¸ì¸", "ìœ¡ì•„", "ì•„ë™ë³µì§€", "ì‚¬íšŒë¬¸ì œ", "ë…¸ë™", "í™˜ê²½ë¬¸ì œ", "ì¸ê¶Œ"],
    '400 ìì—°ê³¼í•™': ["ìˆ˜í•™", "ë¬¼ë¦¬", "í™”í•™", "ìƒë¬¼", "ì§€êµ¬ê³¼í•™", "ê³¼í•™", "ì²œë¬¸", "ê¸°í›„", "ì˜í•™", "ìƒëª…ê³¼í•™"],
    '500 ê¸°ìˆ ê³¼í•™': ["ê±´ê°•", "ì˜ë£Œ", "ìš”ë¦¬", "ê°„í˜¸", "ê³µí•™", "ì»´í“¨í„°", "AI", "IT", "ë†ì—…", "ì¶•ì‚°", "ì‚°ì—…", "ê¸°ìˆ ", "ë¯¸ìš©"],
    '600 ì˜ˆìˆ ': ["ë¯¸ìˆ ", "ìŒì•…", "ë¬´ìš©", "ì‚¬ì§„", "ì˜í™”", "ì—°ê·¹", "ë””ìì¸", "ê³µì˜ˆ", "ì˜ˆìˆ ", "ë¬¸í™”ì˜ˆìˆ "],
    '700 ì–¸ì–´': ["ì–¸ì–´", "êµ­ì–´", "ì˜ì–´", "ì¼ë³¸ì–´", "ì¤‘êµ­ì–´", "ì™¸êµ­ì–´", "í•œì", "ë¬¸ë²•"],
    '800 ë¬¸í•™': ["ì†Œì„¤", "ì‹œ", "ìˆ˜í•„", "ì—ì„¸ì´", "í¬ê³¡", "ë¬¸í•™", "ë™í™”", "ì›¹íˆ°", "íŒíƒ€ì§€", "ë¬¸ì˜ˆ"],
    '900 ì—­ì‚¬Â·ì§€ë¦¬': ["ì—­ì‚¬", "ì§€ë¦¬", "í•œêµ­ì‚¬", "ì„¸ê³„ì‚¬", "ì—¬í–‰", "ë¬¸í™”ìœ ì‚°", "ê´€ê´‘"],
    'ì›ì„œ(ì˜ì–´)': ["ì›ì„œ", "ì˜ë¬¸ë„ì„œ", "ì˜ë¬¸íŒ", "ì˜ì–´ì›ì„œ"],
    'ì—°ì†ê°„í–‰ë¬¼': ["ì¡ì§€", "ê°„í–‰ë¬¼", "ì—°ì†ê°„í–‰ë¬¼"],
    'í•´ë‹¹ì—†ìŒ': []
}

def is_trivial(text):
    text = str(text).strip()
    return text in ["", "X", "x", "ê°ì‚¬í•©ë‹ˆë‹¤", "ê°ì‚¬", "ì—†ìŒ"]

def split_keywords_simple(text):
    parts = re.split(r"[.,/\s]+", text)
    return [p.strip() for p in parts if len(p.strip()) > 1]

def map_keyword_to_category(keyword):
    for cat, kws in KDC_KEYWORD_MAP.items():
        if any(k in keyword for k in kws):
            return cat
    return "í•´ë‹¹ì—†ìŒ"

def escape_tildes(text: str, mode: str = "html") -> str:
    """
    mode="html": ì¹´ë“œì²˜ëŸ¼ HTMLë¡œ ë Œë”ë§í•  ë•Œ ë¬¼ê²°í‘œ ì²˜ë¦¬.
    mode="markdown": st.markdown ê°™ì€ ë§ˆí¬ë‹¤ìš´ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì·¨ì†Œì„  ë°©ì§€.
    """
    if mode == "html":
        # '~~' ë¨¼ì € ë°”ê¾¸ê³  ë‹¨ì¼ ~ë„ ì—”í‹°í‹°ë¡œ
        text = text.replace("~~", "&#126;&#126;")
        return text.replace("~", "&#126;")
    else:  # markdown
        text = text.replace("~~", r"\~\~")
        return text.replace("~", r"\~")

def safe_markdown(text, **kwargs):
    # ë§ˆí¬ë‹¤ìš´ ì·¨ì†Œì„  ë°©ì§€ë¥¼ ìœ„í•´ ~ë¥¼ ì´ìŠ¤ì¼€ì´í”„
    safe = escape_tildes(text, mode="markdown")
    st.markdown(safe, **kwargs)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# DataFrame & visualization helpers
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _sanitize_dataframe_for_streamlit(df: pd.DataFrame) -> pd.DataFrame:
    df2 = df.copy()

    for col in df2.select_dtypes(include=["object"]).columns:
        df2[col] = df2[col].apply(lambda x: str(x) if not pd.isna(x) else x)

    if isinstance(df2.index, pd.MultiIndex):
        df2.index = df2.index.map(lambda tup: " | ".join(map(str, tup)))
    else:
        df2.index = df2.index.map(lambda x: str(x))

    df2.columns = [str(c) for c in df2.columns]
    return df2

def render_chart_and_table(bar, table, title, key_prefix=""):
    if bar is not None:
        st.plotly_chart(bar, use_container_width=True, key=f"{key_prefix}-bar-{title}")
    if isinstance(table, go.Figure):
        st.plotly_chart(table, use_container_width=True, key=f"{key_prefix}-tbl-fig-{title}")
    elif isinstance(table, pd.DataFrame):
        try:
            safe_tbl = _sanitize_dataframe_for_streamlit(table)
            st.dataframe(safe_tbl, key=f"{key_prefix}-tbl-df-{title}")
        except Exception as e:
            logging.warning(f"DataFrame rendering failed, showing head only: {e}")
            try:
                safe_head = _sanitize_dataframe_for_streamlit(table.head(200))
                st.dataframe(safe_head, key=f"{key_prefix}-tbl-df-{title}-sample")
                st.warning(f"ì „ì²´ í…Œì´ë¸” ë Œë”ë§ì— ì‹¤íŒ¨í•˜ì—¬ ìƒìœ„ 200ê°œë§Œ ë³´ì—¬ì¤ë‹ˆë‹¤: {e}")
            except Exception as e2:
                st.error(f"í…Œì´ë¸” ë Œë”ë§ ë¶ˆê°€: {e2}")
    elif table is not None:
        st.write(table, key=f"{key_prefix}-tbl-raw-{title}")

def show_table(df, caption):
    st.dataframe(df)


def render_insight_card(title: str, content: str, key: str = None):
    if content is None:
        content = "(ë‚´ìš© ì—†ìŒ)"
    content = str(content)
    content_html = escape_tildes(content, mode="html").replace("\n", "<br>")
    line_count = content.count("\n") + 3
    height = min(800, 70 + 20 * line_count)
    html = f"""
    <div style="
        border:1px solid #e2e8f0;
        border-radius:12px;
        padding:16px;
        margin-bottom:16px;
        background: #ffffff;
        box-shadow: 0 8px 24px rgba(0,0,0,0.04);
        font-family: system-ui, -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', Arial;
    ">
        <h4 style="margin:0 0 8px 0; font-size:1.1rem;">{title}</h4>
        <div style="font-size:0.95em; line-height:1.4em;">{content_html}</div>
    </div>
    """
    try:
        components.html(html, height=height, key=key)
    except Exception as e:
        logging.warning(f"components.html failed for key={key}: {e}")
        # Fallback so the user still sees something
        st.markdown(f"**{title}**\n\n{content}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Likert / ì¤‘ë¶„ë¥˜ ì ìˆ˜ ê³„ì‚°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def scale_likert(series):
    return 100 * (pd.to_numeric(series, errors='coerce') - 1) / 6

MIDDLE_CATEGORY_MAPPING = {
    "ê³µê°„ ë° ì´ìš©í¸ì˜ì„±":       lambda col: str(col).startswith("Q1-"),
    "ì •ë³´ íšë“ ë° í™œìš©":       lambda col: str(col).startswith("Q2-"),
    "ì†Œí†µ ë° ì •ì±… í™œìš©":       lambda col: str(col).startswith("Q3-"),
    "ë¬¸í™”Â·êµìœ¡ í–¥ìœ ":         lambda col: str(col).startswith("Q4-"),
    "ì‚¬íšŒì  ê´€ê³„ í˜•ì„±":       lambda col: str(col).startswith("Q5-"),
    "ê°œì¸ì˜ ì‚¶ê³¼ ì—­ëŸ‰":       lambda col: str(col).startswith("Q6-"),
    "ë„ì„œê´€ì˜ ê³µìµì„± ë° ê¸°ì—¬ë„": lambda col: (str(col).startswith("Q7-") or str(col).startswith("Q8")),
}

@st.cache_data(show_spinner=False)
def compute_midcategory_scores(df):
    results = {}
    for mid, predicate in MIDDLE_CATEGORY_MAPPING.items():
        cols = [c for c in df.columns if predicate(c)]
        if not cols:
            continue
        scaled = df[cols].apply(scale_likert)
        mid_mean = scaled.mean(axis=0, skipna=True).mean()
        results[mid] = mid_mean
    return pd.Series(results).dropna()

@st.cache_data(show_spinner=False)
def compute_within_category_item_scores(df):
    item_scores = {}
    for mid, predicate in MIDDLE_CATEGORY_MAPPING.items():
        cols = [c for c in df.columns if predicate(c)]
        if not cols:
            continue
        scaled = df[cols].apply(scale_likert)
        item_means = scaled.mean(axis=0, skipna=True)
        item_scores[mid] = item_means
    return item_scores

def midcategory_avg_table(df):
    s = compute_midcategory_scores(df)
    if s.empty:
        return pd.DataFrame()
    tbl = s.rename("í‰ê·  ì ìˆ˜(0~100)").to_frame().reset_index().rename(columns={"index": "ì¤‘ë¶„ë¥˜"})
    tbl["í‰ê·  ì ìˆ˜(0~100)"] = tbl["í‰ê·  ì ìˆ˜(0~100)"].round(2)
    tbl = tbl.sort_values(by="í‰ê·  ì ìˆ˜(0~100)", ascending=False).reset_index(drop=True)
    return tbl

def plot_midcategory_radar(df):
    mid_scores = compute_midcategory_scores(df)
    if mid_scores.empty:
        return None
    categories = list(mid_scores.index)
    values = mid_scores.values.tolist()
    categories_closed = categories + categories[:1]
    values_closed = values + values[:1]
    overall_mean = mid_scores.mean()
    avg_values_closed = [overall_mean] * len(categories_closed)

    fig = go.Figure()
    fig.add_trace(go.Scatterpolar(
        r=values_closed,
        theta=categories_closed,
        fill='toself',
        name='ì¤‘ë¶„ë¥˜ ë§Œì¡±ë„',
        hovertemplate="%{theta}: %{r:.1f}<extra></extra>"
    ))
    fig.add_trace(go.Scatterpolar(
        r=avg_values_closed,
        theta=categories_closed,
        fill=None,
        name=f"ì „ì²´ í‰ê·  ({overall_mean:.1f})",
        line=dict(color='red', dash='solid'),
        hovertemplate=f"ì „ì²´ í‰ê· : {overall_mean:.1f}<extra></extra>"
    ))
    fig.update_layout(
        polar=dict(radialaxis=dict(range=[0,100], tickformat=".0f")),
        title="ì¤‘ë¶„ë¥˜ë³„ ë§Œì¡±ë„ ìˆ˜ì¤€ (0~100 í™˜ì‚°, ë ˆì´ë” ì°¨íŠ¸)",
        showlegend=True,
        height=450,
        margin=dict(t=40, b=20)
    )
    return fig

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# GPT ê´€ë ¨ í—¬í¼
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def cohen_d(x, y):
    x = np.array(x.dropna(), dtype=float)
    y = np.array(y.dropna(), dtype=float)
    nx, ny = len(x), len(y)
    if nx < 2 or ny < 2:
        return None
    # pooled standard deviation
    pooled = np.sqrt(((nx - 1) * x.var(ddof=1) + (ny - 1) * y.var(ddof=1)) / (nx + ny - 2)) if (nx + ny - 2) > 0 else 0
    if pooled == 0:
        return 0.0
    return (x.mean() - y.mean()) / pooled

def compare_midcategory_by_group(df, group_col):
    """
    group_col ê¸°ì¤€ìœ¼ë¡œ ê° ê·¸ë£¹ì˜ ì¤‘ë¶„ë¥˜ ë§Œì¡±ë„ë¥¼ ì „ì²´ ë‚˜ë¨¸ì§€ì™€ ë¹„êµí•˜ì—¬
    mean, delta, Welch t-test p-value, Cohen's d, sample sizeë¥¼ ê³„ì‚°.
    ë°˜í™˜ í˜•íƒœ: {group_label: {midcategory: {mean, delta_vs_overall, p_value_vs_rest, cohen_d_vs_rest, n}}}
    """
    results = {}
    global_mid = compute_midcategory_scores(df)
    
    # per-row midcategory scores (ê° ì‘ë‹µìë³„ë¡œ ì¤‘ë¶„ë¥˜ ì ìˆ˜ ê³„ì‚°)
    def per_row_mid_scores(subdf):
        per_mid = {}
        for mid, predicate in MIDDLE_CATEGORY_MAPPING.items():
            cols = [c for c in subdf.columns if predicate(c)]
            if not cols:
                continue
            scaled = subdf[cols].apply(scale_likert)
            per_mid[mid] = scaled.mean(axis=1, skipna=True)
        return per_mid  # dict of Series

    # ì „ì²´ ë°ì´í„° ê¸°ì¤€ per-row
    overall_per_row = per_row_mid_scores(df)

    for group_value, sub in df.groupby(df[group_col].astype(str)):
        group_per_row = per_row_mid_scores(sub)
        group_summary = {}
        for mid in global_mid.index:
            if mid not in group_per_row or mid not in overall_per_row:
                continue
            grp_scores = group_per_row[mid].dropna()
            rest_mask = df[group_col].astype(str) != str(group_value)
            rest = df[rest_mask]
            rest_per_row = per_row_mid_scores(rest).get(mid, pd.Series(dtype=float)).dropna()
            if grp_scores.empty or rest_per_row.empty:
                continue
            # Welch's t-test
            try:
                stat, p = stats.ttest_ind(grp_scores, rest_per_row, equal_var=False)
            except Exception:
                p = None
            d = cohen_d(grp_scores, rest_per_row)
            mean_group = compute_midcategory_scores(sub).get(mid, None)
            delta = None
            if mean_group is not None and mid in global_mid:
                delta = mean_group - global_mid.get(mid)
            group_summary[mid] = {
                "mean": round(float(mean_group), 1) if mean_group is not None else None,
                "delta_vs_overall": round(float(delta), 1) if delta is not None else None,
                "p_value_vs_rest": round(p, 4) if p is not None else None,
                "cohen_d_vs_rest": round(d, 2) if d is not None else None,
                "n": int(len(grp_scores))
            }
        results[str(group_value)] = group_summary
    return results


@st.cache_data(show_spinner=False)
def process_answers(responses):
    expanded = []
    for ans in responses:
        if is_trivial(ans):
            continue
        parts = [p.strip() for p in ans.split(',') if p.strip()]
        if len(parts) > 1:
            expanded.extend(parts)
        else:
            expanded.append(ans)

    processed = []
    batches = extract_keyword_and_audience(expanded, batch_size=8)
    for resp, kws, aud in batches:
        if is_trivial(resp):
            continue
        if not kws:
            kws = split_keywords_simple(resp)
        for kw in kws:
            cat = map_keyword_to_category(kw)
            if cat == 'í•´ë‹¹ì—†ìŒ' and aud == 'ì¼ë°˜':
                continue
            processed.append({
                'ì‘ë‹µ': resp,
                'í‚¤ì›Œë“œ': kw,
                'ì£¼ì œë²”ì£¼': cat,
                'ëŒ€ìƒë²”ì£¼': aud
            })
    return pd.DataFrame(processed)

@st.cache_data(show_spinner=False)
def extract_keyword_and_audience(responses, batch_size=20):
    results = []
    for i in range(0, len(responses), batch_size):
        batch = responses[i:i+batch_size]
        prompt = f"""
ë‹¹ì‹ ì€ ë„ì„œê´€ ììœ ì‘ë‹µì—ì„œ ì•„ë˜ í˜•ì‹ì˜ JSON ë°°ì—´ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.
ê° ê°ì²´ëŠ” ì‘ë‹µ, í‚¤ì›Œë“œ ëª©ë¡(1~3ê°œ), ëŒ€ìƒì¸µ(ìœ ì•„/ì•„ë™/ì²­ì†Œë…„/ì¼ë°˜)ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.

ì˜ˆì‹œOutput:
[
  {{"response": "ì‘ë‹µ1", "keywords": ["í‚¤ì›Œë“œ1","í‚¤ì›Œë“œ2"], "audience": "ì²­ì†Œë…„"}},
  ...
]

ì‘ë‹µ ëª©ë¡:
{chr(10).join(f"{j+1}. {txt}" for j, txt in enumerate(batch))}
"""
        try:
            resp = safe_chat_completion(
                model="gpt-4.1-nano",
                messages=[{"role": "system", "content": prompt}],
                temperature=0.2,
                max_tokens=300
            )
            content = resp.choices[0].message.content.strip()
            try:
                data = pd.read_json(content)
            except Exception:
                raise ValueError("JSON íŒŒì‹± ì‹¤íŒ¨, fallbackìœ¼ë¡œ ì „í™˜")
        except Exception:
            # fallback
            data = []
            for txt in batch:
                kws = split_keywords_simple(txt)
                audience = 'ì¼ë°˜'
                for w in ['ì–´ë¦°ì´', 'ì´ˆë“±']:
                    if w in txt:
                        audience = 'ì•„ë™'
                for w in ['ìœ ì•„', 'ë¯¸ì·¨í•™', 'ê·¸ë¦¼ì±…']:
                    if w in txt:
                        audience = 'ìœ ì•„'
                for w in ['ì²­ì†Œë…„', 'ì§„ë¡œ', 'ìê¸°ê³„ë°œ']:
                    if w in txt:
                        audience = 'ì²­ì†Œë…„'
                data.append({
                    'response': txt,
                    'keywords': kws,
                    'audience': audience
                })
            data = pd.DataFrame(data)
        for _, row in data.iterrows():
            results.append((row['response'], row['keywords'], row['audience']))
    return results

def call_gpt_for_insight(prompt, model="gpt-4.1-nano", temperature=0.2, max_tokens=1000):
    try:
        resp = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ì „ëµ ë¦¬í¬íŠ¸ ì‘ì„±ìì´ë©°, ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ëª…í™•í•˜ê³  ê°„ê²°í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•´ì•¼ í•œë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=temperature,
            max_tokens=max_tokens,
        )
        content = resp.choices[0].message.content.strip()
        return content
    except Exception as e:
        logging.warning(f"GPT í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return f"GPT í•´ì„ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}"

def build_radar_prompt(overall_profile: dict, combos: list):
    # combos: list of dicts with keys: label (e.g. "ì—¬ì„± | 30-34ì„¸"), n, profile (dict of midcat->score)
    overall_str = ", ".join(f"{k}: {v:.1f}" for k, v in overall_profile.items())
    combo_lines = []
    for c in combos:
        prof = ", ".join(f"{k}: {v:.1f}" for k, v in c["profile"].items())
        combo_lines.append(f"{c['label']} (ì‘ë‹µììˆ˜={c['n']}): {prof}")
    combo_str = "\n".join(combo_lines)
    prompt = f"""
ë„ˆëŠ” ì „ëµ ë³´ê³ ì„œ ì‘ì„±ìë‹¤. ë‹¤ìŒ ë°ì´í„°ë¥¼ ë³´ê³  'ë ˆì´ë” ì°¨íŠ¸ í•´ì„' ì„¹ì…˜ì„ ë§Œë“¤ì–´ì¤˜.

ì…ë ¥:
- ì „ì²´ í‰ê·  ì¤‘ë¶„ë¥˜ ë§Œì¡±ë„: {overall_str}
- ìƒìœ„ ì„¸ê·¸ë¨¼íŠ¸ ì¡°í•©ë³„ ì¤‘ë¶„ë¥˜ ë§Œì¡±ë„ í”„ë¡œíŒŒì¼:
{combo_str}

ìš”ì²­:
1. ê° ì¡°í•©ëª…(ì˜ˆ: 'ì—¬ì„± | 30-34ì„¸')ì„ ì¤‘ì‹¬ìœ¼ë¡œ, ì „ì²´ í‰ê· ê³¼ ë¹„êµí•´ ê·¸ ì¡°í•©ì´ ì–´ë””ì—ì„œ ê°•ì (ë§Œì¡±)ì´ê³  ì–´ë””ì—ì„œ ì•½ì (ë¶ˆë§Œì¡±)ì¸ì§€ ê°ê° 2-3ë¬¸ì¥ì”© ì„¤ëª…í•´ì¤˜. ì¡°í•©ëª…ì„ ë°˜ë³µí•´ì„œ ì‚¬ìš©í•˜ê³ , ìƒëŒ€ì ìœ¼ë¡œ ì–´ë–¤ì§€(ì˜ˆ: â€œì—¬ì„± | 30-34ì„¸ëŠ” ì •ë³´ íšë“ì´ ì „ì²´ í‰ê· ë³´ë‹¤ ë†’ì•„ ê°•ì ì´ë‚˜, ì†Œí†µ ë° ì •ì±… í™œìš©ì—ì„œëŠ” ë‚®ì•„ ë³´ì™„ í•„ìš”â€) í‘œí˜„í•´ì¤˜.
2. ì„œë¡œ ëšœë ·íˆ ëŒ€ë¹„ë˜ëŠ” ë‘ ê°œì˜ ì¡°í•©ëª… ìŒì„ ê³¨ë¼ ë¹„êµ ì„¤ëª…í•´ì¤˜. ê°ê° ì–´ë–¤ ì¤‘ë¶„ë¥˜ì—ì„œ ì°¨ì´ê°€ ë‚˜ëŠ”ì§€, ê·¸ë¡œë¶€í„° ì–´ë–¤ ì¸ì‚¬ì´íŠ¸ê°€ ë‚˜ì˜¤ëŠ”ì§€ êµ¬ì²´ì ìœ¼ë¡œ ì„œìˆ .
3. ì „ì²´ì ìœ¼ë¡œ ê´€ì°°ë˜ëŠ” íŒ¨í„´ 3ê°œë¥¼ ë„ì¶œí•´ì¤˜. (ì˜ˆ: â€œíŠ¹ì • ì—°ë ¹ëŒ€ ì¡°í•©ë“¤ì´ ì •ë³´ íšë“ì€ ë†’ì§€ë§Œ ì†Œí†µì—ì„œ ì¼ê´€ë˜ê²Œ ë‚®ìŒâ€ì²˜ëŸ¼ ì¡°í•© íŠ¹ì„± í¬í•¨)
4. ì „ëµì  ì‹œì‚¬ì  3ê°œ: ì–´ë–¤ ì¡°í•©ì„ ìš°ì„  ê³µëµ/ë³´ì™„í• ì§€, ì¡°í•©ëª…ì„ ëª…ì‹œí•˜ë©° êµ¬ì²´ì  í–‰ë™ ë°©í–¥ì„ ì œì•ˆí•´ì¤˜.
5. ì „ì²´ ê¸¸ì´ëŠ” 2000ìë¡œ ì œí•œë¼. ê·¸ë¦¬ê³  ì‘ì„±ê°„ì— "~"ëŠ” ëª¨ë‘ "-" ë¡œ í‘œì‹œë˜ì–´ì•¼í•´. 

ìŠ¤íƒ€ì¼: ë¹„ì¦ˆë‹ˆìŠ¤ ë³´ê³ ì„œ í†¤, ì†Œì œëª© í¬í•¨, ìˆ«ìëŠ” í•œ ìë¦¬ ì†Œìˆ˜, ì¡°í•©ëª…(ì˜ˆ: 'ì—¬ì„± | 30-34ì„¸')ì„ ëª¨ë“  ì„¤ëª…ì— ëª…ì‹œí•˜ê³  â€˜ì¡°í•© 1â€™ ê°™ì€ ì¼ë°˜ëª…ì€ ì“°ì§€ ë§ˆ."""
    return prompt.strip()

def build_heatmap_prompt(table_df: pd.DataFrame, midcats: list):
    # table_df: DataFrame with columns including "ì¡°í•©", "ì‘ë‹µììˆ˜", and each midcat
    rows = []
    for _, r in table_df.iterrows():
        label = r.get("ì¡°í•©", "")
        n = int(r.get("ì‘ë‹µììˆ˜", 0))
        scores = ", ".join(f"{mc}: {r.get(mc, 0):.1f}" for mc in midcats)
        rows.append(f"{label} (ì‘ë‹µììˆ˜={n}): {scores}")
    table_str = "\n".join(rows)
    prompt = f"""
ë„ˆëŠ” ì „ëµ ë³´ê³ ì„œ ì‘ì„±ìë‹¤. ì•„ë˜ íˆíŠ¸ë§µìš© ë°ì´í„°ë¥¼ ë³´ê³  ì¸ì‚¬ì´íŠ¸ë¥¼ ì •ë¦¬í•´ì¤˜. ëª¨ë“  ì„¤ëª…ì—ì„œ ì¡°í•©ëª…(ì˜ˆ: 'ì—¬ì„± | 30-34ì„¸')ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì“°ê³ , ì¼ë°˜ì ì¸ 'ì¡°í•© A/B' ê°™ì€ í‘œí˜„ì€ í”¼í•˜ê³  êµ¬ì²´ì ì¸ ì´ë¦„ê³¼ ë¹„êµë¥¼ ë°˜ë³µí•´ì¤˜.

ì…ë ¥:
- ì„¸ê·¸ë¨¼íŠ¸ ì¡°í•©ë³„ ì¤‘ë¶„ë¥˜ë³„ í‰ê·  ë§Œì¡±ë„:
{table_str}

ìš”ì²­:
1. ì ìˆ˜ê°€ ëª°ë ¤ ìˆëŠ” êµ°ì§‘(ì˜ˆ: íŠ¹ì • ì¡°í•©ëª…ë“¤ì´ ì—¬ëŸ¬ ì¤‘ë¶„ë¥˜ì—ì„œ ëª¨ë‘ ë†’ì€ íŒ¨í„´ ë˜ëŠ” ë‚®ì€ íŒ¨í„´)ì„ ì´ë¦„(ì¡°í•©ëª…)ê³¼ í•¨ê»˜ ì •ë¦¬í•´ì¤˜. ì–´ë–¤ ì¡°í•©ëª…ë“¤ì´ ë¹„ìŠ·í•œ ê°•ì /ì•½ì ì„ ê³µìœ í•˜ëŠ”ì§€ë„ ë¬¶ì–´ì„œ ì¨ì¤˜.
2. ì‘ë‹µì ìˆ˜ê°€ ì¶©ë¶„í•œ ì¡°í•©ëª…ë“¤ì—ì„œ ì¼ê´€ëœ ê°•ì ê³¼ ì•½ì ì„ ê°ê° ìš”ì•½í•´ì¤˜. ì˜ˆ: 'ì—¬ì„± | 30-34ì„¸'ëŠ” ì •ë³´ íšë“ê³¼ ê³µìµì„±ì—ì„œ ì¼ê´€ë˜ê²Œ ë†’ê³ , ì†Œí†µ ë° ì •ì±… í™œìš©ì´ ë‚®ìŒ.
3. ì „ì²´ì ì¸ ì¤‘ë¶„ë¥˜ë³„ ê²½í–¥: ì–´ë–¤ ì¤‘ë¶„ë¥˜ê°€ ì „ë°˜ì ìœ¼ë¡œ ë†’ì€ì§€/ë‚®ì€ì§€, ê·¸ë¦¬ê³  íŠ¹ì • ì¡°í•©ëª…ë“¤ì´ ê·¸ íë¦„ê³¼ ì–´ë–»ê²Œ ë‹¤ë¥¸ì§€ ì„¤ëª…í•´ì¤˜.
4. ìš”ì•½ ê°œìš” (í•œ ë¬¸ë‹¨)ê³¼, ë„ì¶œí•  ìˆ˜ ìˆëŠ” 3ê°œì˜ êµ¬ì²´ì ì¸ í–‰ë™ ê¶Œì¥ì (ì¡°í•©ëª…ì„ í¬í•¨í•œ ìš°ì„ ìˆœìœ„ í¬í•¨)ì„ ì œì‹œí•´ì¤˜.
5. ì „ì²´ ê¸¸ì´ëŠ” 2000ìë¡œ ì œí•œë¼. ê·¸ë¦¬ê³  ì‘ì„±ê°„ì— "~"ëŠ” ëª¨ë‘ "-" ë¡œ í‘œì‹œë˜ì–´ì•¼í•´. 


ìŠ¤íƒ€ì¼: ë¹„ì¦ˆë‹ˆìŠ¤ ë¦¬í¬íŠ¸ í†¤, ì†Œì œëª© í¬í•¨, ìˆ«ìëŠ” í•œ ìë¦¬ ì†Œìˆ˜, ì¡°í•©ëª…ì„ ë°˜ë³µì ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ ë¹„êµÂ·ëŒ€ì¡° ì¤‘ì‹¬ìœ¼ë¡œ ì‘ì„±."""
    return prompt.strip()

def build_delta_prompt(delta_df: pd.DataFrame, midcats: list):
    # delta_df: DataFrame indexed by "ì¡°í•©", with columns like "<midcat>_delta"
    rows = []
    for _, r in delta_df.iterrows():
        combo = r.name  # ì¡°í•©ëª…
        diffs = ", ".join(f"{mc}: {r.get(f'{mc}_delta', 0):+.1f}" for mc in midcats)
        rows.append(f"{combo}: {diffs}")
    table_str = "\n".join(rows)
    prompt = f"""
ë„ˆëŠ” ì „ëµ ë³´ê³ ì„œ ì‘ì„±ìë‹¤. ì•„ë˜ ë°ì´í„°ëŠ” ì„¸ê·¸ë¨¼íŠ¸ ì¡°í•©ëª…ë³„ ì¤‘ë¶„ë¥˜ ë§Œì¡±ë„ê°€ ì „ì²´ í‰ê·  ëŒ€ë¹„ ì–¼ë§ˆë‚˜ ë²—ì–´ë‚˜ëŠ”ì§€(Delta)ë¥¼ ë³´ì—¬ì¤€ë‹¤. ëª¨ë“  ì„¤ëª…ì—ì„œ ì¡°í•©ëª…(ì˜ˆ: 'ì—¬ì„± | 30-34ì„¸')ì„ ë°˜ë³µ ì‚¬ìš©í•˜ì—¬, ê°•í•˜ê²Œ ë²—ì–´ë‚œ ì˜ì—­ê³¼ ê·¸ ë°˜ë³µì  íŒ¨í„´ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì„œìˆ í•´ì¤˜.

ì…ë ¥:
{table_str}

ìš”ì²­:
1. ê° ì¡°í•©ëª…ë³„ë¡œ ì „ì²´ í‰ê·  ëŒ€ë¹„ ê°€ì¥ ê³¼ë„í•˜ê²Œ ë†’ì€/ë‚®ì€ ì¤‘ë¶„ë¥˜ë¥¼ ëª…í™•íˆ ì§šì–´ì¤˜. ì˜ˆ: 'ì—¬ì„± | 30-34ì„¸ëŠ” ì •ë³´ íšë“ì—ì„œ +12.3ìœ¼ë¡œ ê°•ì ì´ë‚˜, ì†Œí†µ ë° ì •ì±… í™œìš©ì—ì„œëŠ” -9.5ë¡œ ì•½ì 'ì²˜ëŸ¼.
2. ì—¬ëŸ¬ ì¡°í•©ëª…ì´ ë°˜ë³µí•´ì„œ ë¹„ìŠ·í•œ í¸ì°¨ íŒ¨í„´(ì˜ˆ: ë™ì¼í•˜ê²Œ íŠ¹ì • ì¤‘ë¶„ë¥˜ê°€ ë‚®ê±°ë‚˜ ë†’ì€)ì„ ë³´ì´ëŠ”ì§€ ê·¸ë£¹í™”í•˜ì—¬ ì„¤ëª…í•´ì¤˜. êµ¬ì²´ì ì¸ ì¡°í•©ëª…ë“¤ì„ ë¬¶ì–´ ë¹„êµ.
3. ê°œì„ /í™•ì¥ ìš°ì„ ìˆœìœ„ë¥¼ ì¡°í•©ëª… ê¸°ì¤€ìœ¼ë¡œ ì¶”ì²œí•´ì¤˜. (ì˜ˆ: 'ì†Œí†µ ë° ì •ì±… í™œìš©ì´ ë°˜ë³µì ìœ¼ë¡œ ë‚®ì€ ì¡°í•©ëª…ë“¤ë¶€í„° ê°œì„ í•´ì•¼ í•˜ë©°, ì¤‘ë¶„ë¥˜ í‰ê·  ëŒ€ë¹„ ë†’ê³  ë¹ˆë²ˆí•œ ì¡°í•©ëª…ë“¤ì— ëŒ€í•´ í™•ì¥ ì „ëµ ê³ ë ¤' ë“±)
4. ì „ì²´ ê¸¸ì´ëŠ” 2000ìë¡œ ì œí•œë¼. ê·¸ë¦¬ê³  ì‘ì„±ê°„ì— "~"ëŠ” ëª¨ë‘ "-" ë¡œ í‘œì‹œë˜ì–´ì•¼í•´. 


ìŠ¤íƒ€ì¼: ê°„ê²°í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ìš”ì•½, ì†Œì œëª© í¬í•¨, ìˆ«ìëŠ” í•œ ìë¦¬ ì†Œìˆ˜, ì¡°í•©ëª… ëª…ì‹œ ì¤‘ì‹¬."""
    return prompt.strip()

def build_ci_prompt(subset_df: pd.DataFrame, mc: str):
    # subset_df: contains columns 'ì¡°í•©', 'delta', 'se' for given midcategory, and maybe ì‘ë‹µììˆ˜
    rows = []
    for _, r in subset_df.iterrows():
        combo = r.get("ì¡°í•©", "")
        delta = r.get("delta", 0)
        se = r.get("se", 0)
        rows.append(f"{combo}: í¸ì°¨ {delta:.1f}, í‘œì¤€ì˜¤ì°¨ {se:.2f}")
    table_str = "\n".join(rows)
    prompt = f"""
ë„ˆëŠ” ì „ëµ ë³´ê³ ì„œ ì‘ì„±ìë‹¤. ì•„ë˜ ë°ì´í„°ëŠ” ì¤‘ë¶„ë¥˜ '{mc}'ì— ëŒ€í•´ ìƒìœ„ ì„¸ê·¸ë¨¼íŠ¸ ì¡°í•©ëª…ë“¤ì´ ì „ì²´ í‰ê·  ëŒ€ë¹„ í¸ì°¨(delta)ì™€ ê·¸ ë¶ˆí™•ì‹¤ì„±(í‘œì¤€ì˜¤ì°¨)ì„ ë‚˜íƒ€ë‚¸ë‹¤. ëª¨ë“  ë¶„ì„ì—ì„œ ì¡°í•©ëª…(ì˜ˆ: 'ì—¬ì„± | 30-34ì„¸')ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë¹„êµí•˜ê³ , ì˜ë¯¸ ìˆëŠ” vs ë¶ˆí™•ì‹¤í•œ ì¼€ì´ìŠ¤ë¥¼ êµ¬ë¶„í•´ì„œ ì„œìˆ í•´ì¤˜.

ì…ë ¥:
{table_str}

ìš”ì²­:
1. ì–´ë–¤ ì¡°í•©ëª…ë“¤ì˜ í¸ì°¨ê°€ 0 ê¸°ì¤€ì„ ê³¼ ë¹„êµí•´ ì‹¤ì§ˆì ìœ¼ë¡œ ì˜ë¯¸ ìˆì–´ ë³´ì´ëŠ”ì§€ ì„¤ëª…í•´ì¤˜. (ì˜ˆ: í‘œì¤€ì˜¤ì°¨ì— ë¹„í•´ í¸ì°¨ê°€ ì¶©ë¶„íˆ í°ì§€ ì—¬ë¶€ë¥¼ ì¡°í•©ëª…ë³„ë¡œ íŒë‹¨)
2. í¸ì°¨ê°€ í¬ì§€ë§Œ ë¶ˆí™•ì‹¤ì„±ì´ í° ì¡°í•©ëª…ê³¼, í¸ì°¨ëŠ” ì‘ì§€ë§Œ ì•ˆì •ì ì¸ ì¡°í•©ëª…ì„ ì¡°í•©ëª… ê¸°ì¤€ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ ë¹„êµ ì„¤ëª…í•´ì¤˜.
3. ìš°ì„  ê°œì…í•˜ê±°ë‚˜ ì£¼ëª©í•´ì•¼ í•  ì¡°í•©ëª… 3ê°œë¥¼ ì¶”ì²œí•´ì¤˜. ê°ê° ì™œ ìš°ì„ ìˆœìœ„ì¸ì§€(í¸ì°¨/ë¶ˆí™•ì‹¤ì„± ê´€ì ) êµ¬ì²´ì ìœ¼ë¡œ ì¨ì¤˜.
4. ì „ì²´ ê¸¸ì´ëŠ” 2000ìë¡œ ì œí•œë¼. ê·¸ë¦¬ê³  ì‘ì„±ê°„ì— "~"ëŠ” ëª¨ë‘ "-" ë¡œ í‘œì‹œë˜ì–´ì•¼í•´. 


ìŠ¤íƒ€ì¼: ë¹„ì¦ˆë‹ˆìŠ¤ ë¦¬í¬íŠ¸ í†¤, ì†Œì œëª© í¬í•¨, ìˆ«ìëŠ” í•œ ìë¦¬ ì†Œìˆ˜, ì¡°í•©ëª…ì„ ë°˜ë³µ ëª…ì‹œí•˜ì—¬ ì½ëŠ” ì‚¬ëŒì´ ë°”ë¡œ ì–´ë–¤ ê·¸ë£¹ì¸ì§€ ì•Œ ìˆ˜ ìˆê²Œ ì‘ì„±."""
    return prompt.strip()

def build_small_multiple_prompt(top_df: pd.DataFrame, midcat: str, segment_cols_filtered: list):
    # top_df: DataFrame with a 'ì¡°í•©' constructed from segment_cols_filtered and midcat scores
    rows = []
    for _, r in top_df.iterrows():
        combo = " | ".join(str(r[c]) for c in segment_cols_filtered)
        score = r.get(midcat, None)
        if pd.notna(score):
            rows.append(f"{combo}: {midcat} ì ìˆ˜ {score:.1f}")
        else:
            rows.append(f"{combo}: ë°ì´í„° ì—†ìŒ")
    table_str = "\n".join(rows)
    prompt = f"""
ë„ˆëŠ” ì „ëµ ë³´ê³ ì„œ ì‘ì„±ìë‹¤. ì•„ë˜ ë°ì´í„°ëŠ” ì¤‘ë¶„ë¥˜ '{midcat}'ì— ëŒ€í•´ ì‘ë‹µì ìˆ˜ ìƒìœ„ ì„¸ê·¸ë¨¼íŠ¸ ì¡°í•©ëª…ë“¤ì˜ ì ìˆ˜ë¥¼ ë¹„êµí•œ ê²ƒì´ë‹¤. ëª¨ë“  ì„¤ëª…ì—ì„œ ì¡°í•©ëª…(ì˜ˆ: 'ì—¬ì„± | 30-34ì„¸')ì„ ì¤‘ì‹¬ìœ¼ë¡œ í•˜ê³ , ì¼ë°˜ì  í‘œí˜„ ì—†ì´ êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ì¡°í•©ì´ ëˆˆì— ë„ëŠ”ì§€, ìˆœìœ„ ë³€ë™ì„±ê³¼ outlierë¥¼ ê¸°ìˆ í•´ì¤˜.

ì…ë ¥:
{table_str}

ìš”ì²­:
1. ì¤‘ë¶„ë¥˜ '{midcat}'ì—ì„œ ì¡°í•©ëª…ë“¤ ê°„ ì ìˆ˜ ë¶„í¬ì™€ ìˆœìœ„ ë³€ë™ì„±ì´ ì–´ë–¤ì§€ ìš”ì•½í•´ì¤˜. (ì˜ˆ: ì–´ë–¤ ì¡°í•©ëª…ì´ ì¼ê´€ë˜ê²Œ ìƒìœ„ì¸ì§€, ì–´ë–¤ ì¡°í•©ëª…ì€ ë³€ë™ì„±ì´ í¬ë©° ë¶ˆì•ˆì •í•œì§€)
2. íŠ¹ì§•ì ì¸ outlier ì¡°í•©ëª…ë“¤ì„ ì§€ì í•˜ê³ , ê·¸ë“¤ì´ ì™œ ì˜ˆì™¸ì ì¸ì§€ ì„¤ëª…í•´ì¤˜. (ì˜ˆ: ë‹¤ë¥¸ ì¡°í•©ëª…ë“¤ë³´ë‹¤ í›¨ì”¬ ë†’ê±°ë‚˜ ë‚®ì€ ê²½ìš°)
3. ì¼ê´€ì„± ìˆëŠ” ê°•ì /ì•½ì ì„ ë³´ì´ëŠ” ì¡°í•©ëª… ê·¸ë£¹ì´ ìˆë‹¤ë©´ ë¬¶ì–´ì„œ ì„¤ëª…í•´ì¤˜. (ì˜ˆ: '30~34ì„¸ ì—¬ì„±' ê³„ì—´ì´ ì •ë³´ íšë“ì€ ë†’ì§€ë§Œ ì†Œí†µì´ ë‚®ì€ íŒ¨í„´)
4. ì „ì²´ ê¸¸ì´ëŠ” 2000ìë¡œ ì œí•œë¼. ê·¸ë¦¬ê³  ì‘ì„±ê°„ì— "~"ëŠ” ëª¨ë‘ "-" ë¡œ í‘œì‹œë˜ì–´ì•¼í•´. 


ìŠ¤íƒ€ì¼: ì§§ê³  ëª…í™•í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ìš”ì•½, ì†Œì œëª© í¬í•¨, ìˆ«ìëŠ” í•œ ìë¦¬ ì†Œìˆ˜, ì¡°í•©ëª…ì„ ë°˜ë³µí•˜ì—¬ ë¹„êµ ì¤‘ì‹¬ìœ¼ë¡œ ì‘ì„±."""
    return prompt.strip()


# ---------- ìì—°ì–´ ì§ˆì˜ ê¸°ë°˜ ìë™ ì‹œê°í™” + ì¸ì‚¬ì´íŠ¸ íŒŒì´í”„ë¼ì¸ ----------

def parse_nl_query_to_spec(question: str):
    system_prompt = """
ë„ˆëŠ” ì„¤ë¬¸ ë°ì´í„°ì— ëŒ€í•œ ìì—°ì–´ ì§ˆì˜ë¥¼ ë°›ì•„ì„œ ì‹œê°í™”/ë¶„ì„ ìŠ¤í™ì„ êµ¬ì¡°í™”ëœ JSONìœ¼ë¡œ ë°”ê¾¸ëŠ” íŒŒì„œì•¼.
ì¶œë ¥ì€ ì˜¤ì§ JSON ê°ì²´ í•˜ë‚˜ë§Œ, ì½”ë“œë¸”ëŸ­ ì—†ì´ ë°˜í™˜í•´. ëª¨ë¥´ë©´ nullì´ë‚˜ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¤ì–´ì¤˜.

í•„ë“œ:
{
  "chart": "bar" / "line" / "heatmap" / "radar" / "delta_bar" / null,
  "x": "ì»¬ëŸ¼ëª… ë˜ëŠ” ì¤‘ë¶„ë¥˜ ì´ë¦„",
  "y": null,
  "groupby": "ì»¬ëŸ¼ëª… (ë¹„êµ ê¸°ì¤€)",
  "filters": [ {"col": "ì»¬ëŸ¼ëª…", "op": "contains"|"=="|"in", "value": "ê°’ ë˜ëŠ” ë¦¬ìŠ¤íŠ¸"} ],
  "focus": "ì„¤ëª…ì—ì„œ ì¤‘ì ì ìœ¼ë¡œ ë‹¤ë£° í¬ì¸íŠ¸"
}

ì˜ˆì‹œ:
1. "í˜¼ì ì´ìš©í•˜ëŠ” ì‚¬ëŒë“¤ì˜ ì—°ë ¹ëŒ€ ë¶„í¬ ë³´ì—¬ì£¼ê³ , ì£¼ë¡œ ê°€ëŠ” ë„ì„œê´€ë³„ ì¤‘ë¶„ë¥˜ ë§Œì¡±ë„ ê°•ì /ì•½ì  ë¹„êµí•´ì¤˜."
   -> {
        "chart": null,
        "x": "SQ2_GROUP",
        "groupby": "SQ4", 
        "filters": [{"col": "ì´ìš©í˜•íƒœ", "op": "contains", "value": "í˜¼ì"}],
        "focus": "í˜¼ì ì´ìš©ì ì—°ë ¹ëŒ€ ë¶„í¬ ë° ì£¼ ì´ìš© ë„ì„œê´€ë³„ ì¤‘ë¶„ë¥˜ ë§Œì¡±ë„ ê°•ì•½ì  ë¹„êµ"
      }
2. "ì „ì²´ í‰ê·  ëŒ€ë¹„ ì–´ë–¤ ì¤‘ë¶„ë¥˜ê°€ ê°•ì ì¸ì§€ ë ˆì´ë”ë¡œ ë³´ì—¬ì¤˜."
   -> {"chart": "radar", "focus": "ì „ì²´ í‰ê·  ëŒ€ë¹„ ì¤‘ë¶„ë¥˜ ê°•ì /ì•½ì  ë¹„êµ"}
3. "ì£¼ì´ìš©ì„œë¹„ìŠ¤ë³„ ì •ë³´ íšë“ê³¼ ì†Œí†µ ë§Œì¡±ë„ ë¹„êµí•´ì¤˜."
   -> {"chart": "grouped_bar", "groupby": "SQ5", "x": "ì¤‘ë¶„ë¥˜", "focus": "ì •ë³´ íšë“ vs ì†Œí†µ ë¹„êµ"}

ë°˜ë“œì‹œ ìì—°ì–´ì—ì„œ ìœ ì¶”í•  ìˆ˜ ìˆëŠ” í•„ë“œë“¤ì„ ì±„ìš°ê³ , focusëŠ” ì‚¬ìš©ì ì˜ë„ë¥¼ ì••ì¶•í•´ì„œ ì§§ê²Œ ì‘ì„±í•´.
"""
    resp = safe_chat_completion(
        model="gpt-4.1",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": question}
        ],
        temperature=0.2,
        max_tokens=300
    )
    content = resp.choices[0].message.content.strip()
    content = re.sub(r"^```|```$", "", content).strip()
    try:
        spec = json.loads(content)
    except Exception:
        spec = {
            "chart": None,
            "x": None,
            "y": None,
            "groupby": None,
            "filters": [],
            "focus": question
        }
    return spec

def infer_chart_type(spec: dict, df_subset: pd.DataFrame):
    # chartì´ ì£¼ì–´ì ¸ ìˆì§€ ì•Šìœ¼ë©´ ìŠ¤í™ + í‚¤ì›Œë“œë¡œ ì¶”ë¡ 
    chart = spec.get("chart")
    focus = spec.get("focus", "").lower() if spec.get("focus") else ""
    groupby = spec.get("groupby")
    x = spec.get("x")
    y = spec.get("y")

    if chart:
        return chart  # ëª…ì‹œì ì´ë©´ ê·¸ëŒ€ë¡œ

    # ì „ì²´ í‰ê·  ëŒ€ë¹„, ê°•ì /ì•½ì  ì–¸ê¸‰: radar + delta ìš°ì„ 
    if any(k in focus for k in ["ì „ì²´ í‰ê·  ëŒ€ë¹„", "ê°•ì ", "ì•½ì ", "ë¹„êµ"]):
        if groupby or x is None:
            return "radar"
        if x and not groupby:
            return "delta_bar"

    # groupby + ì¤‘ë¶„ë¥˜ ë¹„êµ
    if groupby and (("ì¤‘ë¶„ë¥˜" in (x or "").lower()) or "ë§Œì¡±ë„" in (focus or "").lower()):
        return "grouped_bar"

    # ë¶„í¬ ê´€ë ¨
    if any(k in focus for k in ["ë¶„í¬", "ì—°ë ¹ëŒ€", "ë¹„ìœ¨", "ë§ì´"]):
        if x:
            return "bar"

    # íŒ¨í„´, êµ°ì§‘ -> heatmap
    if any(k in focus for k in ["íŒ¨í„´", "êµ°ì§‘", "ë¹„ìŠ·í•œ", "ì°¨ì´"]):
        return "heatmap"

    # default fallback
    return "bar"

def generate_explanation_from_spec(df_subset: pd.DataFrame, spec: dict, computed_metrics: dict, extra_group_stats=None):
    focus = spec.get("focus", "ê¸°ë³¸ ìš”ì•½")
    parts = []
    if "overall_mid_scores" in computed_metrics:
        mids = computed_metrics["overall_mid_scores"]
        parts.append("ì „ì²´ ì¤‘ë¶„ë¥˜ í‰ê· : " + ", ".join(f"{k} {v:.1f}" for k, v in mids.items()))
    if "deltas" in computed_metrics:
        deltas = computed_metrics["deltas"]
        delta_str = ", ".join(f"{k} {v:+.1f}" for k, v in deltas.items())
        parts.append("ì „ì²´ í‰ê·  ëŒ€ë¹„ í¸ì°¨: " + delta_str)
    if "top_segments" in computed_metrics:
        top = computed_metrics["top_segments"]
        parts.append("ì£¼ìš” ì„¸ê·¸ë¨¼íŠ¸/ì¡°í•©: " + "; ".join(f"{t['label']} (n={t['n']})" for t in top))
    if extra_group_stats:
        summary_lines = []
        for group_label, mids in extra_group_stats.items():
            for mid, stats in mids.items():
                line = f"{group_label}ì˜ '{mid}' í‰ê·  {stats.get('mean')}, ì „ì²´ ëŒ€ë¹„ {stats.get('delta_vs_overall'):+.1f}"
                if stats.get("p_value_vs_rest") is not None:
                    line += f", p={stats['p_value_vs_rest']}"
                if stats.get("cohen_d_vs_rest") is not None:
                    line += f", d={stats['cohen_d_vs_rest']}"
                summary_lines.append(line)
        parts.append("ê·¸ë£¹ ë¹„êµ: " + " / ".join(summary_lines[:3]))  # ê¸¸ì´ ì œí•œ ê°ì•ˆ

    summary_context = "\n".join(parts)
    prompt = f"""
ë„ˆëŠ” ì „ëµ ë¦¬í¬íŠ¸ ì‘ì„±ìë‹¤. ì•„ë˜ ì»¨í…ìŠ¤íŠ¸ì™€ ì‚¬ìš©ì ì§ˆì˜ í¬ì»¤ìŠ¤ë¥¼ ì°¸ê³ í•´ ëª…í™•í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ë§Œë“¤ì–´ì¤˜.

ì‚¬ìš©ì ì§ˆì˜ í¬ì»¤ìŠ¤: {spec.get('focus', '')}

ë°ì´í„° ìš”ì•½:
{summary_context}

ìš”ì²­:
1. ì£¼ìš” ê´€ì°° íŒ¨í„´ 2~3ê°œë¥¼ ê¸°ìˆ í•´ì¤˜.
2. ê°•ì ê³¼ ì•½ì ì„ êµ¬ì²´ì ì¸ í•­ëª©ëª…ì´ë‚˜ ì„¸ê·¸ë¨¼íŠ¸ëª…ì„ ìˆ«ìì™€ í•¨ê»˜ ì„¤ëª…í•´ì¤˜.
3. ìš°ì„  ê°œì…/í™•ì¥í• ë§Œí•œ í–‰ë™ ì œì•ˆ 2ê°œë¥¼ ì œì‹œí•´ì¤˜.
4. ì „ì²´ ê¸¸ì´ 500~1000ì, ë¹„ì¦ˆë‹ˆìŠ¤ í†¤, ìˆ«ìëŠ” í•œ ìë¦¬ ì†Œìˆ˜, '-' ì‚¬ìš©.

ì¶œë ¥ë§Œ í…ìŠ¤íŠ¸ë¡œ í•´ì¤˜.
"""
    explanation = call_gpt_for_insight(prompt)
    return explanation.replace("~", "-")


def apply_filters(df: pd.DataFrame, filters: list):
    dff = df.copy()
    for f in filters:
        col = f.get("col")
        op = f.get("op", "==")
        val = f.get("value")
        if col not in dff.columns or val is None:
            continue
        if op in ("==", "="):
            dff = dff[dff[col].astype(str) == str(val)]
        elif op == "in" and isinstance(val, list):
            dff = dff[dff[col].astype(str).isin([str(v) for v in val])]
        elif op == "contains":
            dff = dff[dff[col].astype(str).str.contains(str(val), na=False)]
    return dff

def handle_nl_question(df: pd.DataFrame, question: str):
    st.markdown("## ìì—°ì–´ ì§ˆì˜ ê²°ê³¼")
    st.markdown(f"**ì§ˆì˜:** {question}")

    spec = parse_nl_query_to_spec(question)
    df_filtered = apply_filters(df, spec.get("filters", []))

    if df_filtered.empty:
        st.warning("í•„í„° ì ìš© ê²°ê³¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì¡°ê±´ì„ ì¡°ì •í•´ë³´ì„¸ìš”.")
        return

    # ì¤‘ë¶„ë¥˜ ê´€ë ¨ ì£¼ìš” ì§€í‘œ
    overall_mid_scores = compute_midcategory_scores(df_filtered)
    overall_mid_dict = {k: float(v) for k, v in overall_mid_scores.items()} if not overall_mid_scores.empty else {}

    # ì „ì²´ í‰ê·  ëŒ€ë¹„ (ì›ë˜ ì „ì²´ ë°ì´í„° ê¸°ì¤€)
    global_mid_scores = compute_midcategory_scores(df)
    deltas = {}
    for k in overall_mid_dict:
        base = float(global_mid_scores.get(k, overall_mid_dict.get(k, 0)))
        deltas[k] = overall_mid_dict.get(k, 0) - base

    # ìƒìœ„ ì¡°í•©/ì„¸ê·¸ë¨¼íŠ¸ ì¶”ì¶œ (ê°„ë‹¨: groupbyê°€ ìˆìœ¼ë©´ ê·¸ ê·¸ë£¹ë³„ ê°œìˆ˜)
    top_segments = []
    gb = spec.get("groupby")
    if gb and gb in df_filtered.columns:
        counts = df_filtered[gb].astype(str).value_counts().nlargest(3)
        for label, n in counts.items():
            subset = df_filtered[df_filtered[gb].astype(str) == label]
            profile = compute_midcategory_scores(subset)
            top_segments.append({"label": f"{gb}={label}", "n": int(n), "profile": {k: float(v) for k, v in profile.items()}})
    else:
        top_segments.append({"label": "í•„í„°ëœ ì „ì²´", "n": len(df_filtered), "profile": overall_mid_dict})

    computed_metrics = {
        "overall_mid_scores": overall_mid_dict,
        "deltas": deltas,
        "top_segments": top_segments
    }

    # ê·¸ë£¹ ë¹„êµ í†µê³„ (groupbyê°€ ìˆìœ¼ë©´)
    extra_group_stats = None
    gb = spec.get("groupby")
    if gb and gb in df_filtered.columns:
        extra_group_stats = compare_midcategory_by_group(df_filtered, gb)

    # ì„¤ëª… ìƒì„± (ê¸°ì¡´ í˜¸ì¶œì„ ì•„ë˜ë¡œ êµì²´)
    explanation = generate_explanation_from_spec(df_filtered, spec, computed_metrics, extra_group_stats=extra_group_stats)
    render_insight_card("ìì—°ì–´ ê¸°ë°˜ ì„¤ëª…", explanation, key="nlq-insight")


    # ì°¨íŠ¸ ìœ í˜• ê²°ì •
    chart_type = infer_chart_type(spec, df_filtered)

    chart = None
    # ì‹œê°í™” ìƒì„± (ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜)
    if chart_type == "radar":
        # ì „ì²´ í‰ê·  + í•„í„°ëœ ì„¸ê·¸ë¨¼íŠ¸ ë ˆì´ë”
        fig = go.Figure()
        midcats = list(overall_mid_scores.index)
        if not midcats:
            st.warning("ì¤‘ë¶„ë¥˜ ì ìˆ˜ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            # ì „ì²´ í‰ê·  (ì›ë³¸ ì „ì²´)
            global_vals = [float(global_mid_scores.get(m, 0)) for m in midcats]
            global_closed = global_vals + [global_vals[0]]
            cats_closed = midcats + [midcats[0]]
            fig.add_trace(go.Scatterpolar(
                r=global_closed,
                theta=cats_closed,
                fill=None,
                name="ì „ì²´ í‰ê· ",
                line=dict(dash="dash", width=2),
                opacity=0.6
            ))
            # í•„í„°ëœ
            vals = [float(overall_mid_scores.get(m, 0)) for m in midcats]
            vals_closed = vals + [vals[0]]
            fig.add_trace(go.Scatterpolar(
                r=vals_closed,
                theta=cats_closed,
                fill='toself',
                name="ì§ˆì˜ ëŒ€ìƒ",
                hovertemplate="%{theta}: %{r:.1f}<extra></extra>"
            ))
            fig.update_layout(
                polar=dict(radialaxis=dict(range=[0, 100])),
                title="ì¤‘ë¶„ë¥˜ ë§Œì¡±ë„ í”„ë¡œíŒŒì¼ ë¹„êµ (ì „ì²´ í‰ê·  vs ëŒ€ìƒ)",
                height=450
            )
            chart = fig

    elif chart_type == "heatmap":
        # ì¤‘ë¶„ë¥˜ í‰ê·  íˆíŠ¸ë§µ (í•„í„°ëœ)
        midcat_prefixes = list(MIDCAT_MAP.values())
        heat_df = df_filtered.copy()
        matrix = {}
        for mc, prefix in MIDCAT_MAP.items():
            if isinstance(prefix, list):
                cols = sum([ [c for c in heat_df.columns if c.startswith(p)] for p in prefix], [])
            else:
                cols = [c for c in heat_df.columns if c.startswith(prefix)]
            if not cols:
                continue
            vals = heat_df[cols].apply(pd.to_numeric, errors="coerce")
            matrix[mc] = round(100 * (vals.mean(axis=1, skipna=True) - 1) / 6).mean() if not vals.empty else None
        if matrix:
            hm_df = pd.DataFrame.from_dict(matrix, orient="index", columns=["í‰ê· ì ìˆ˜"])
            fig = px.imshow(
                hm_df.T,
                text_auto=True,
                aspect="auto",
                color_continuous_scale="Blues",
                title="ì¤‘ë¶„ë¥˜ í‰ê·  íˆíŠ¸ë§µ (ì§ˆì˜ ëŒ€ìƒ ê¸°ì¤€)",
                labels=dict(x="ì¤‘ë¶„ë¥˜", y="", color="ì ìˆ˜")
            )
            chart = fig

    elif chart_type in ("grouped_bar", "bar"):
        # ê¸°ë³¸ x ê¸°ì¤€ ë§‰ëŒ€ or groupby+ì¤‘ë¶„ë¥˜ ë¹„êµ
        x = spec.get("x")
        groupby = spec.get("groupby")
        if groupby and groupby in df_filtered.columns:
            # groupbyë³„ ì¤‘ë¶„ë¥˜ ë§Œì¡±ë„ ë¹„êµ
            rows = []
            midcats = list(MIDDLE_CATEGORY_MAPPING.keys())
            for val, sub in df_filtered.groupby(df_filtered[groupby].astype(str)):
                scores = compute_midcategory_scores(sub)
                for m in scores.index:
                    rows.append({
                        groupby: val,
                        "ì¤‘ë¶„ë¥˜": m,
                        "ë§Œì¡±ë„": float(scores.get(m, 0)),
                        "ì „ì²´ í‰ê· ": float(global_mid_scores.get(m, 0))
                    })
            if rows:
                plot_df = pd.DataFrame(rows)
                fig = px.bar(
                    plot_df,
                    x="ì¤‘ë¶„ë¥˜",
                    y="ë§Œì¡±ë„",
                    color=groupby,
                    barmode="group",
                    title=f"{groupby}ë³„ ì¤‘ë¶„ë¥˜ ë§Œì¡±ë„ ë¹„êµ",
                    text="ë§Œì¡±ë„"
                )
                avg_df = plot_df.drop_duplicates(subset=["ì¤‘ë¶„ë¥˜"])[["ì¤‘ë¶„ë¥˜", "ì „ì²´ í‰ê· "]]
                fig.add_trace(go.Scatter(
                    x=avg_df["ì¤‘ë¶„ë¥˜"],
                    y=avg_df["ì „ì²´ í‰ê· "],
                    mode="lines+markers",
                    name="ì „ì²´ í‰ê· ",
                    line=dict(dash="dash"),
                    hovertemplate="%{x}: %{y:.1f}<extra></extra>"
                ))
                fig.update_traces(texttemplate="%{text:.1f}", textposition="outside")
                chart = fig
        elif x and x in df_filtered.columns:
            cnt = df_filtered[x].astype(str).value_counts().reset_index()
            cnt.columns = [x, "count"]
            fig = px.bar(cnt, x=x, y="count", title=f"{x} ë¶„í¬", text="count")
            fig.update_traces(textposition="outside")
            chart = fig

    else:
        st.warning("ìë™ìœ¼ë¡œ ì ì ˆí•œ ì‹œê°í™”ë¥¼ ì¶”ë¡ í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    
    if chart is not None:
        st.plotly_chart(chart, use_container_width=True)
    else:
        st.info("ìƒì„±í•  ì°¨íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")

    explanation = generate_explanation_from_spec(df_filtered, spec, computed_metrics)
    render_insight_card("ìì—°ì–´ ê¸°ë°˜ ì„¤ëª…", explanation, key="nlq-insight")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì„¸ê·¸ë¨¼íŠ¸ íŒŒìƒ/ë§¤í•‘
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def add_derived_columns(df):
    df = df.copy()
    if "DQ1_FREQ" not in df.columns:
        dq1_cols = [c for c in df.columns if "DQ1" in c]
        if dq1_cols:
            dq1_col = dq1_cols[0]
            monthly = pd.to_numeric(df[dq1_col].astype(str).str.extract(r"(\d+\.?\d*)")[0], errors="coerce")
            yearly = monthly * 12
            bins = [0,12,24,48,72,144,1e10]
            labels = ["0~11íšŒ: ì—° 1íšŒ ë¯¸ë§Œ", "12~23íšŒ: ì›” 1íšŒ", "24~47íšŒ: ì›” 2~4íšŒ", "48~71íšŒ: ì£¼ 1íšŒ", "72~143íšŒ: ì£¼ 2~3íšŒ", "144íšŒ ì´ìƒ: ê±°ì˜ ë§¤ì¼"]
            df["DQ1_FREQ"] = pd.cut(yearly, bins=bins, labels=labels, right=False)
    if "DQ2_YEARS" not in df.columns or "DQ2_YEARS_GROUP" not in df.columns:
        dq2_cols = [c for c in df.columns if "DQ2" in c]
        if dq2_cols:
            dq2_col = dq2_cols[0]
            def parse_years(s):
                s = str(s)
                m = re.match(r'^(\d+)\s*ë…„\s*(\d+)\s*ê°œì›”$', s)
                if m: return int(m.group(1)) + (1 if int(m.group(2)) > 0 else 0)
                m = re.match(r'^(\d+)\s*ë…„$', s)
                if m: return int(m.group(1))
                m = re.match(r'^(\d+)\s*ê°œì›”$', s)
                if m: return 1
                return None
            years = df[dq2_col].dropna().apply(parse_years)
            df["DQ2_YEARS"] = years

        def year_group(y):
            if pd.isna(y):
                return None
            y = int(y)
            if y < 5:
                return "1~4ë…„"
            elif y < 10:
                return "5~9ë…„"
            elif y < 15:
                return "10~14ë…„"
            elif y < 20:
                return "15~19ë…„"
            else:
                return "20ë…„ ì´ìƒ"
        df["DQ2_YEARS_GROUP"] = df["DQ2_YEARS"].apply(year_group)

    if "DQ4_1ST" not in df.columns:
        dq4_cols = [c for c in df.columns if ("DQ4" in c) and ("1ìˆœìœ„" in c)]
        if dq4_cols:
            df["DQ4_1ST"] = df[dq4_cols[0]]

    if "SQ2_GROUP" not in df.columns:
        sq2_cols = [c for c in df.columns if "SQ2" in c]
        if sq2_cols:
            sq2_col = sq2_cols[0]
            data = df[sq2_col].dropna().astype(str).str.extract(r'(\d+)')
            data.columns = ['age']
            data['age'] = pd.to_numeric(data['age'], errors='coerce')
            def age_group(age):
                if pd.isna(age):
                    return None
                age = int(age)
                if age < 15:
                    return '14ì„¸ ì´í•˜'
                elif age >= 80:
                    return '80ì„¸ ì´ìƒ'
                else:
                    base = (age // 5) * 5
                    return f"{base}~{base+4}ì„¸"
            df["SQ2_GROUP"] = data['age'].apply(age_group)
    return df

def get_segment_columns(df, key):
    if key == "DQ2":
        if "DQ2_YEARS_GROUP" in df.columns:
            return ["DQ2_YEARS_GROUP"]
        elif "DQ2_YEARS" in df.columns:
            return ["DQ2_YEARS"]
        return [col for col in df.columns if "DQ2" in col]
    elif key == "DQ4":
        return [col for col in df.columns if ("DQ4" in col) and ("1ìˆœìœ„" in col)]
    elif key == "DQ1":
        if "DQ1_FREQ" in df.columns:
            return ["DQ1_FREQ"]
        return [col for col in df.columns if "DQ1" in col]
    else:
        return [col for col in df.columns if key in col]

SEGMENT_OPTIONS = [
    {"label": "SQ1. ì„±ë³„",        "key": "SQ1"},
    {"label": "SQ2. ì—°ë ¹",        "key": "SQ2"},
    {"label": "SQ3. ê±°ì£¼ì§€",      "key": "SQ3"},
    {"label": "SQ4. ì£¼ ì´ìš© ë„ì„œê´€", "key": "SQ4"},
    {"label": "SQ5. ì£¼ë¡œ ì´ìš© ì„œë¹„ìŠ¤", "key": "SQ5"},
    {"label": "DQ1. ì›”í‰ê·  ì´ìš© ë¹ˆë„", "key": "DQ1"},
    {"label": "DQ2. ì´ìš©ê¸°ê°„", "key": "DQ2"},
    {"label": "DQ4. (1ìˆœìœ„)ì´ìš©ëª©ì ", "key": "DQ4"},
]
MIDCAT_MAP = {
    "ê³µê°„ ë° ì´ìš©í¸ì˜ì„±": "Q1-",
    "ì •ë³´ íšë“ ë° í™œìš©": "Q2-",
    "ì†Œí†µ ë° ì •ì±… í™œìš©": "Q3-",
    "ë¬¸í™”Â·êµìœ¡ í–¥ìœ ": "Q4-",
    "ì‚¬íšŒì  ê´€ê³„ í˜•ì„±": "Q5-",
    "ê°œì¸ì˜ ì‚¶ê³¼ ì—­ëŸ‰": "Q6-",
    "ìì¹˜êµ¬ êµ¬ì„± ë¬¸í•­": "Q9-D-3",
    "ê³µìµì„± ë° ê¸°ì—¬ë„": ["Q7-", "Q8-"],
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì‹œê°í™” í•¨ìˆ˜ë“¤
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def plot_age_histogram_with_labels(df, question):
    data = df[question].dropna().astype(str).str.extract(r'(\d+)')
    data.columns = ['age']
    data['age'] = pd.to_numeric(data['age'], errors='coerce').dropna()

    def age_group(age):
        if age < 15:
            return '14ì„¸ ì´í•˜'
        elif age >= 80:
            return '80ì„¸ ì´ìƒ'
        else:
            return f"{(age//5)*5}~{(age//5)*5+4}ì„¸"

    data['group'] = data['age'].apply(age_group)
    grouped = data['group'].value_counts().sort_index()
    percent = (grouped / grouped.sum() * 100).round(1)

    fig = go.Figure(go.Bar(
        x=grouped.index, y=grouped.values,
        text=grouped.values, textposition='outside',
        marker_color=get_qualitative_colors(1)[0]
    ))
    fig.update_layout(
        title=question, yaxis_title="ì‘ë‹µ ìˆ˜",
        bargap=0.1, height=450, margin=dict(t=40, b=10)
    )

    table_df = pd.DataFrame({'ì‘ë‹µ ìˆ˜': grouped, 'ë¹„ìœ¨ (%)': percent}).T
    return fig, table_df

def plot_bq2_bar(df, question):
    data = df[question].dropna().astype(str)
    counts_raw = data.value_counts()
    percent_raw = (counts_raw / counts_raw.sum() * 100).round(1)

    categories_raw = counts_raw.index.tolist()
    categories = [label.split('. ', 1)[-1] for label in categories_raw]
    counts = counts_raw.values
    percent = percent_raw.values

    wrapped_labels = [wrap_label(remove_parentheses(label), width=10) for label in categories]

    colors = get_qualitative_colors(len(categories))
    fig = go.Figure(go.Bar(
        x=categories,
        y=counts,
        text=counts,
        textposition='outside',
        marker_color=colors
    ))
    y_max = counts.max() + 20
    fig.update_layout(
        title=dict(text=question, font=dict(size=16)),
        yaxis=dict(title="ì‘ë‹µ ìˆ˜", range=[0, y_max]),
        height=450,
        margin=dict(t=50, b=100),
        xaxis_tickangle=-30
    )

    table_df = pd.DataFrame(
        [counts, percent],
        index=["ì‘ë‹µ ìˆ˜", "ë¹„ìœ¨ (%)"],
        columns=wrapped_labels
    )
    return fig, table_df

def plot_sq4_custom_bar(df, question):
    data = df[question].dropna().astype(str)
    cats = sorted(data.unique())
    counts = data.value_counts().reindex(cats).fillna(0).astype(int)
    percent = (counts / counts.sum() * 100).round(1)
    display_labels = [wrap_label(remove_parentheses(x), 10) for x in cats]

    fig = go.Figure()
    colors = get_qualitative_colors(len(cats))
    for i, cat in enumerate(cats):
        fig.add_trace(go.Bar(
            x=[percent[cat]], y=[question],
            orientation='h', name=remove_parentheses(cat),
            marker_color=colors[i],
            text=f"{percent[cat]}%", textposition='inside'
        ))
    fig.update_layout(
        barmode='stack', showlegend=True,
        legend=dict(orientation='h', y=-0.5, x=0.5, xanchor='center', traceorder='reversed'),
        title=dict(text=question, font=dict(size=16)),
        yaxis=dict(showticklabels=False),
        height=250, margin=dict(t=40, b=100)
    )

    table_df = pd.DataFrame(
        [counts.values, percent.values],
        index=["ì‘ë‹µ ìˆ˜", "ë¹„ìœ¨ (%)"],
        columns=display_labels
    )
    return fig, table_df

def plot_categorical_stacked_bar(df, question):
    data = df[question].dropna().astype(str)
    categories_raw = sorted(data.unique())
    display_labels = [label.split('. ', 1)[-1] for label in categories_raw]

    counts = data.value_counts().reindex(categories_raw).fillna(0).astype(int)
    percent = (counts / counts.sum() * 100).round(1)

    fig = go.Figure()
    colors = get_qualitative_colors(len(display_labels))
    for i, (raw_cat, label) in enumerate(zip(categories_raw, display_labels)):
        fig.add_trace(go.Bar(
            x=[percent[raw_cat]],
            y=[question],
            orientation='h',
            name=label,
            marker=dict(color=colors[i]),
            text=f"{percent[raw_cat]}%",
            textposition='inside',
            insidetextanchor='middle',
            hoverinfo='x+name'
        ))


    fig.update_layout(
        barmode='stack',
        showlegend=True,
        legend=dict(
            orientation='h',
            yanchor='bottom', y=-1,
            xanchor='center', x=0.5,
            traceorder='reversed'
        ),
        title=dict(text=question, font=dict(size=16)),
        yaxis=dict(showticklabels=False),
        height=250, margin=dict(t=40, b=100)
    )

    table_df = pd.DataFrame(
        [counts.values, percent.values],
        index=["ì‘ë‹µ ìˆ˜", "ë¹„ìœ¨ (%)"],
        columns=display_labels
    )
    return fig, table_df

def plot_stacked_bar_with_table(df, question):
    data = pd.to_numeric(df[question].dropna(), errors='coerce').dropna().astype(int)
    order = [1,2,3,4,5,6,7]
    counts = data.value_counts().reindex(order, fill_value=0)
    percent = (counts / counts.sum() * 100).round(1)

    colors = {
        1: "#d73027", 2: "#fc8d59", 3: "#fee090",
        4: "#dddddd", 5: "#91bfdb", 6: "#4575b4", 7: "#313695"
    }
    fig = go.Figure()
    for v in order:
        fig.add_trace(go.Bar(
            x=[percent[v]], y=[question], orientation='h', name=f"{v}ì ",
            marker_color=colors[v], text=f"{percent[v]}%", textposition='inside'
        ))
    fig.update_layout(
        barmode='stack', showlegend=False,
        title=question, xaxis_title="ë§¤ìš° ë¶ˆë§Œì¡± â†’ ë§¤ìš° ë§Œì¡±",
        yaxis=dict(showticklabels=False), height=180, margin=dict(t=40,b=2)
    )

    table_df = pd.DataFrame(
        [counts.values, percent.values],
        index=["ì‘ë‹µ ìˆ˜", "ë¹„ìœ¨ (%)"],
        columns=[f"{v}ì " for v in order]
    )
    return fig, table_df

def show_short_answer_keyword_analysis(df_result):
    st.subheader("ğŸ“˜ Q9-DS-4 ë‹¨ë¬¸ ì‘ë‹µ í‚¤ì›Œë“œ ë¶„ì„")
    order = list(KDC_KEYWORD_MAP.keys())
    df_cat = df_result.groupby("ì£¼ì œë²”ì£¼")["í‚¤ì›Œë“œ"].count().reindex(order, fill_value=0).reset_index(name="ë¹ˆë„ìˆ˜")
    fig = px.bar(df_cat, x="ì£¼ì œë²”ì£¼", y="ë¹ˆë„ìˆ˜", title="ì£¼ì œë²”ì£¼ë³„ í‚¤ì›Œë“œ ë¹ˆë„", text="ë¹ˆë„ìˆ˜")
    fig.update_traces(textposition="outside")
    st.plotly_chart(fig, use_container_width=True)
    df_aud = df_result.groupby("ëŒ€ìƒë²”ì£¼")["í‚¤ì›Œë“œ"].count().reset_index(name="ë¹ˆë„ìˆ˜")
    fig2 = px.bar(df_aud, x="ëŒ€ìƒë²”ì£¼", y="ë¹ˆë„ìˆ˜", title="ëŒ€ìƒë²”ì£¼ë³„ í‚¤ì›Œë“œ ë¹ˆë„", text="ë¹ˆë„ìˆ˜", color="ëŒ€ìƒë²”ì£¼")
    fig2.update_traces(textposition="outside")
    st.plotly_chart(fig2, use_container_width=True)
    st.markdown("#### ğŸ” ë¶„ì„ ê²°ê³¼ í…Œì´ë¸”")
    st.dataframe(df_result[["ì‘ë‹µ", "í‚¤ì›Œë“œ", "ì£¼ì œë²”ì£¼", "ëŒ€ìƒë²”ì£¼"]])

def plot_within_category_bar(df, midcategory):
    item_scores = compute_within_category_item_scores(df)
    if midcategory not in item_scores:
        return None, None
    predicate = MIDDLE_CATEGORY_MAPPING[midcategory]
    orig_cols = [c for c in df.columns if predicate(c)]
    if not orig_cols:
        return None, None

    series_plot = item_scores[midcategory].reindex(orig_cols[::-1])
    series_table = item_scores[midcategory].reindex(orig_cols)
    mid_scores = compute_midcategory_scores(df)
    mid_mean = mid_scores.get(midcategory, None)

    wrapped_labels = [wrap_label_fixed(label, width=35) for label in series_plot.index]

    fig = go.Figure()
    fig.add_trace(go.Bar(
        x=series_plot.values,
        y=wrapped_labels,
        orientation='h',
        text=series_plot.round(1),
        textposition='outside',
        marker_color='steelblue',
        hovertemplate="<b>%{customdata}</b><br>í‰ê·  ì ìˆ˜: %{x:.1f}<extra></extra>",
        customdata=series_plot.index
    ))
    if mid_mean is not None:
        fig.add_vline(x=mid_mean, line_color="red")

    per_item_height = 50
    total_height = max(300, per_item_height * len(wrapped_labels))

    fig.update_layout(
        title=f"{midcategory} ë‚´ ë¬¸í•­ë³„ í‰ê·  ì ìˆ˜ ë¹„êµ (0~100 í™˜ì‚°)",
        xaxis_title=f"{midcategory} í‰ê·  {mid_mean:.2f}" if mid_mean is not None else "í‰ê·  ì ìˆ˜",
        margin=dict(t=40, b=60),
        height=total_height
    )

    if mid_mean is not None:
        diff = series_table - mid_mean
        table_df = pd.DataFrame({
            'í‰ê·  ì ìˆ˜': series_table.round(2),
            'ì¤‘ë¶„ë¥˜ í‰ê· ': [round(mid_mean,2)] * len(series_table),
            'í¸ì°¨ (ë¬¸í•­ - ì¤‘ë¶„ë¥˜ í‰ê· )': diff.round(2)
        }, index=series_table.index)
    else:
        table_df = pd.DataFrame({
            'í‰ê·  ì ìˆ˜': series_table.round(2)
        }, index=series_table.index)
    return fig, table_df

def plot_dq1(df):
    cols = [c for c in df.columns if c.startswith("DQ1")]
    if not cols:
        return None, None, ""
    question = cols[0]
    data = df[question].dropna().astype(str).str.extract(r"(\d+\.?\d*)")[0]
    monthly = pd.to_numeric(data, errors='coerce')
    yearly = monthly * 12

    def categorize(f):
        try:
            f = float(f)
        except:
            return None
        if f < 12:
            return "0~11íšŒ: ì—° 1íšŒ ë¯¸ë§Œ"
        elif f < 24:
            return "12~23íšŒ: ì›” 1íšŒ ì •ë„"
        elif f < 48:
            return "24~47íšŒ: ì›” 2~4íšŒ ì •ë„"
        elif f < 72:
            return "48~71íšŒ: ì£¼ 1íšŒ ì •ë„"
        elif f < 144:
            return "72~143íšŒ: ì£¼ 2~3íšŒ"
        else:
            return "144íšŒ ì´ìƒ: ê±°ì˜ ë§¤ì¼"

    cat = yearly.apply(categorize)
    order = ["0~11íšŒ: ì—° 1íšŒ ë¯¸ë§Œ","12~23íšŒ: ì›” 1íšŒ ì •ë„","24~47íšŒ: ì›” 2~4íšŒ ì •ë„",
             "48~71íšŒ: ì£¼ 1íšŒ ì •ë„","72~143íšŒ: ì£¼ 2~3íšŒ","144íšŒ ì´ìƒ: ê±°ì˜ ë§¤ì¼"]
    grp = cat.value_counts().reindex(order, fill_value=0)
    pct = (grp/grp.sum()*100).round(1)

    fig = go.Figure(go.Bar(x=grp.index, y=grp.values, text=grp.values,
                            textposition='outside', marker_color=get_qualitative_colors(1)[0]))
    fig.update_layout(title=question, xaxis_title="ì´ìš© ë¹ˆë„ êµ¬ê°„", yaxis_title="ì‘ë‹µ ìˆ˜",
                      bargap=0.2, height=450, margin=dict(t=30,b=50), xaxis_tickangle=-15)

    tbl_df = pd.DataFrame({"ì‘ë‹µ ìˆ˜":grp, "ë¹„ìœ¨ (%)":pct}).T
    return fig, tbl_df, question

def plot_dq2(df):
    cols = [c for c in df.columns if c.startswith("DQ2")]
    if not cols:
        return None, None, ""
    question = cols[0]

    def parse(s):
        s = str(s).strip()
        m = re.match(r'^(\d+)\s*ë…„\s*(\d+)\s*ê°œì›”$', s)
        if m:
            return int(m.group(1)) + (1 if int(m.group(2))>0 else 0)
        m = re.match(r'^(\d+)\s*ë…„$', s)
        if m:
            return int(m.group(1))
        m = re.match(r'^(\d+)\s*ê°œì›”$', s)
        if m:
            return 1
        return None

    yrs = df[question].dropna().apply(parse)
    grp = yrs.value_counts().sort_index()
    pct = (grp/grp.sum()*100).round(1)
    labels = [f"{y}ë…„" for y in grp.index]
    fig = go.Figure(go.Bar(x=labels, y=grp.values, text=grp.values,
                            textposition='outside', marker_color=get_qualitative_colors(1)[0]))
    fig.update_layout(title=question, xaxis_title="ì´ìš© ê¸°ê°„ (ë…„)", yaxis_title="ì‘ë‹µ ìˆ˜",
                      bargap=0.2, height=450, margin=dict(t=30,b=50), xaxis_tickangle=-15)
    tbl_df = pd.DataFrame({"ì‘ë‹µ ìˆ˜":grp, "ë¹„ìœ¨ (%)":pct}).T
    return fig, tbl_df, question

def plot_dq3(df):
    cols = [c for c in df.columns if c.startswith("DQ3")]
    if not cols:
        return None, None, ""
    question = cols[0]
    bar, table_df = plot_categorical_stacked_bar(df[[question]].dropna().astype(str), question)
    return bar, table_df, question

def plot_dq4_bar(df):
    cols = [c for c in df.columns if c.startswith("DQ4")]
    if len(cols) < 2:
        return None, None, ""
    col1, col2 = cols[0], cols[1]
    question = f"{col1} vs {col2}"

    s1 = df[col1].dropna().astype(str)
    s2 = df[col2].dropna().astype(str)
    cats = sorted(set(s1.unique()).union(s2.unique()))
    labels = [c.split('. ',1)[-1] if '. ' in c else c for c in cats]

    counts1 = s1.value_counts().reindex(cats, fill_value=0)
    counts2 = s2.value_counts().reindex(cats, fill_value=0)
    pct1 = (counts1 / counts1.sum() * 100).round(1)
    pct2 = (counts2 / counts2.sum() * 100).round(1)

    order_idx = counts1.sort_values(ascending=False).index.tolist()
    sorted_labels = [lbl.split('. ',1)[-1] if '. ' in lbl else lbl for lbl in order_idx]
    sorted_counts1 = counts1.reindex(order_idx)
    sorted_counts2 = counts2.reindex(order_idx)
    sorted_pct1 = pct1.reindex(order_idx)
    sorted_pct2 = pct2.reindex(order_idx)

    fig = go.Figure()
    fig.add_trace(go.Bar(
        x=sorted_labels, y=sorted_counts1.values,
        name='1ìˆœìœ„', marker_color="#1f77b4", text=sorted_counts1.values, textposition='outside'
    ))
    fig.add_trace(go.Bar(
        x=sorted_labels, y=sorted_counts2.values,
        name='2ìˆœìœ„', marker_color="#2ca02c", text=sorted_counts2.values, textposition='outside'
    ))
    fig.update_layout(
        barmode='stack',
        title="DQ4. ë„ì„œê´€ ì´ìš© ì£¼ìš” ëª©ì  1ìˆœìœ„ vs 2ìˆœìœ„",
        xaxis_title="ì´ìš© ëª©ì ",
        yaxis_title="ì‘ë‹µì ìˆ˜",
        height=550,
        margin=dict(t=40, b=10),
        xaxis_tickangle=-23
    )

    table_df = pd.DataFrame({
        '1ìˆœìœ„ ì‘ë‹µ ìˆ˜': sorted_counts1.values,
        '1ìˆœìœ„ ë¹„ìœ¨(%)': sorted_pct1.values,
        '2ìˆœìœ„ ì‘ë‹µ ìˆ˜': sorted_counts2.values,
        '2ìˆœìœ„ ë¹„ìœ¨(%)': sorted_pct2.values
    }, index=sorted_labels).T
    return fig, table_df, question

def plot_dq5(df):
    cols = [c for c in df.columns if c.startswith("DQ5")]
    if not cols:
        return None, None, ""
    question = cols[0]
    temp_df = df[[question]].dropna().astype(str)
    fig, table_df = plot_categorical_stacked_bar(temp_df, question)
    return fig, table_df, question

def plot_likert_diverging(df, prefix="DQ7-E"):
    cols = [c for c in df.columns if c.startswith(prefix)]
    if not cols:
        return None, None
    dist = {}
    for col in cols:
        counts = df[col].dropna().astype(int).value_counts().reindex(range(1,8), fill_value=0)
        pct = (counts / counts.sum() * 100).round(1)
        dist[col] = pct
    likert_df = pd.DataFrame(dist).T
    likert_df = likert_df.reindex(columns=range(1,8))

    fig = go.Figure()
    neg_scores = [4,3,2,1]
    neg_colors = ["#dddddd","#91bfdb","#4575b4","#313695"]
    for score, color in zip(neg_scores, neg_colors):
        fig.add_trace(go.Bar(
            y=likert_df.index,
            x=-likert_df[score],
            name=f"{score}ì ",
            orientation='h',
            marker_color=color
        ))
    fig.add_trace(go.Bar(
        y=likert_df.index,
        x=likert_df[5],
        name="5ì ",
        orientation='h',
        marker_color="#fee090"
    ))
    for score, color in zip([6,7],["#fc8d59","#d73027"]):
        fig.add_trace(go.Bar(
            y=likert_df.index,
            x=likert_df[score],
            name=f"{score}ì ",
            orientation='h',
            marker_color=color
        ))

    fig.add_vline(
        x=0,
        line_color="black",
        line_width=2,
        line_dash="solid"
    )

    fig.update_layout(
        barmode='relative',
        title="DQ7-E ë„ì„œê´€ ì´ë¯¸ì§€ ë¶„í¬ (ë‹¤ì´ë²„ì§• ë°”)",
        xaxis=dict(visible=False),
        legend=dict(traceorder='normal'),
        height=250,
        margin=dict(t=30, b=5),
    )

    table_df = likert_df.copy()
    return fig, table_df

def plot_pair_bar(df, prefix):
    cols = [c for c in df.columns if c.startswith(prefix)]
    if len(cols) < 2:
        return None, None, ""
    col1, col2 = cols[0], cols[1]
    question = f"{col1} vs (2ìˆœìœ„)"
    s1 = df[col1].dropna().astype(str)
    s2 = df[col2].dropna().astype(str)
    cats = sorted(set(s1.unique()).union(s2.unique()))
    labels = [c.split('. ',1)[-1] if '. ' in c else c for c in cats]

    counts1 = s1.value_counts().reindex(cats, fill_value=0)
    counts2 = s2.value_counts().reindex(cats, fill_value=0)
    pct1 = (counts1 / counts1.sum() * 100).round(1)
    pct2 = (counts2 / counts2.sum() * 100).round(1)

    fig = go.Figure()
    fig.add_trace(go.Bar(x=labels, y=counts1, name='1ìˆœìœ„', marker_color="#1f77b4", text=counts1, textposition='outside'))
    fig.add_trace(go.Bar(x=labels, y=counts2, name='2ìˆœìœ„', marker_color="#2ca02c", text=counts2, textposition='outside'))
    fig.update_layout(
        barmode='stack',
        title=f"{question}",
        yaxis_title="ì‘ë‹µì ìˆ˜",
        height=550,
        margin=dict(t=50, b=70),
        xaxis_tickangle=-23
    )

    table_df = pd.DataFrame({
        '1ìˆœìœ„ ì‘ë‹µ ìˆ˜': counts1.values,
        '1ìˆœìœ„ ë¹„ìœ¨(%)': pct1.values,
        '2ìˆœìœ„ ì‘ë‹µ ìˆ˜': counts2.values,
        '2ìˆœìœ„ ë¹„ìœ¨(%)': pct2.values
    }, index=labels).T
    return fig, table_df, question

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í˜ì´ì§€ êµ¬ì¡°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def page_home(df):
    st.subheader("ğŸ‘¤ ì¸êµ¬í†µê³„ ë¬¸í•­ (SQ1 ~ 5 / BQ1 ~ 2)")
    soc_qs = [c for c in df.columns if c.startswith("SQ") or c.startswith("BQ")]
    for q in soc_qs:
        try:
            if q.startswith("SQ2"):
                bar, table_df = plot_age_histogram_with_labels(df, q)
            elif q.startswith("BQ2"):
                bar, table_df = plot_bq2_bar(df, q)
            elif q.startswith("SQ4"):
                bar, table_df = plot_sq4_custom_bar(df, q)
            else:
                bar, table_df = plot_categorical_stacked_bar(df, q)
            render_chart_and_table(bar, table_df, q, key_prefix="home")
            st.divider()
        except Exception as e:
            st.error(f"{q} ì—ëŸ¬: {e}")

def page_basic_vis(df):
    st.subheader("ğŸ“ˆ 7ì  ì²™ë„ ë§Œì¡±ë„ ë¬¸í•­ (Q1 ~ Q8)")
    likert_qs = [
        col for col in df.columns
        if re.match(r"Q[1-9][\.-]", str(col))
    ]
    section_mapping = {
        "ê³µê°„ ë° ì´ìš©í¸ì˜ì„±":       [q for q in likert_qs if q.startswith("Q1-")],
        "ì •ë³´ íšë“ ë° í™œìš©":       [q for q in likert_qs if q.startswith("Q2-")],
        "ì†Œí†µ ë° ì •ì±… í™œìš©":       [q for q in likert_qs if q.startswith("Q3-")],
        "ë¬¸í™”Â·êµìœ¡ í–¥ìœ ":         [q for q in likert_qs if q.startswith("Q4-")],
        "ì‚¬íšŒì  ê´€ê³„ í˜•ì„±":       [q for q in likert_qs if q.startswith("Q5-")],
        "ê°œì¸ì˜ ì‚¶ê³¼ ì—­ëŸ‰":       [q for q in likert_qs if q.startswith("Q6-")],
        "ë„ì„œê´€ì˜ ê³µìµì„± ë° ê¸°ì—¬ë„": [
            q for q in likert_qs 
            if q.startswith("Q7-") or q.startswith("Q8")
        ]
    }
    tabs2 = st.tabs(list(section_mapping.keys()))
    for tab, section_name in zip(tabs2, section_mapping.keys()):
        with tab:
            st.markdown(f"### {section_name}")
            for q in section_mapping[section_name]:
                try:
                    bar, table_df = plot_stacked_bar_with_table(df, q)
                    render_chart_and_table(bar, table_df, q, key_prefix="basic")
                except Exception as e:
                    st.error(f"{q} ì—ëŸ¬: {e}")
            st.divider()

def page_short_keyword(df):
    with st.spinner("ğŸ” GPT ê¸°ë°˜ í‚¤ì›Œë“œ ë¶„ì„ ì¤‘..."):
        target_cols = [col for col in df.columns if "Q9-DS-4" in col]
        if not target_cols:
            st.warning("Q9-DS-4 ê´€ë ¨ ë¬¸í•­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        answers = df[target_cols[0]].dropna().astype(str).tolist()
        df_result = process_answers(answers)
        show_short_answer_keyword_analysis(df_result)

CATEGORY_MAP = {
    "ê³µê°„ ë° ì´ìš©í¸ì˜ì„±": "Q1",
    "ì •ë³´ íšë“ ë° í™œìš©": "Q2",
    "ì†Œí†µ ë° ì •ì±… í™œìš©": "Q3",
    "ë¬¸í™”Â·êµìœ¡ í–¥ìœ ": "Q4",
    "ì‚¬íšŒì  ê´€ê³„ í˜•ì„±": "Q5",
    "ê°œì¸ì˜ ì‚¶ê³¼ ì—­ëŸ‰": "Q6",
}
TYPE_MAP = {
    "A": "ì„œë¹„ìŠ¤ í‰ê°€",
    "B": "ì„œë¹„ìŠ¤ íš¨ê³¼",
    "C": "ì „ë°˜ì  ë§Œì¡±ë„",
}

def get_abc_category_means(df):
    result = []
    for cat, prefix in CATEGORY_MAP.items():
        for t in ["A", "B", "C"]:
            if t == "C":
                cols = [c for c in df.columns if c.startswith(f"{prefix}-C")]
            else:
                cols = [c for c in df.columns if c.startswith(f"{prefix}-{t}-")]
            if not cols:
                mean_val = None
            else:
                vals = df[cols].apply(pd.to_numeric, errors='coerce')
                mean_val = 100 * (vals.mean(axis=1, skipna=True) - 1) / 6
                mean_val = mean_val.mean()
            result.append({
                "ì¤‘ë¶„ë¥˜": cat,
                "ë¬¸í•­ìœ í˜•": TYPE_MAP[t],
                "í‰ê· ê°’": round(mean_val, 2) if mean_val is not None else None
            })
    return pd.DataFrame(result)

def plot_abc_radar(df_mean):
    categories = df_mean['ì¤‘ë¶„ë¥˜'].unique().tolist()
    fig = go.Figure()
    color_map = {
        "ì„œë¹„ìŠ¤ í‰ê°€": "#2ca02c",
        "ì„œë¹„ìŠ¤ íš¨ê³¼": "#1f77b4",
        "ì „ë°˜ì  ë§Œì¡±ë„": "#d62728"
    }
    for t in TYPE_MAP.values():
        vals = df_mean[df_mean['ë¬¸í•­ìœ í˜•'] == t].set_index('ì¤‘ë¶„ë¥˜').reindex(categories)['í‰ê· ê°’'].tolist()
        fig.add_trace(go.Scatterpolar(
            r=vals + [vals[0]],
            theta=categories + [categories[0]],
            fill='none',
            name=t,
            line=dict(color=color_map.get(t, None)),
        ))
    fig.update_layout(
        polar=dict(radialaxis=dict(range=[50, 100])),
        title="ì¤‘ë¶„ë¥˜ë³„ ì„œë¹„ìŠ¤ í‰ê°€/íš¨ê³¼/ë§Œì¡±ë„ (A/B/C) ë ˆì´ë”ì°¨íŠ¸",
        showlegend=True,
        height=450
    )
    return fig

def plot_abc_grouped_bar(df_mean):
    fig = px.bar(
        df_mean,
        x='ì¤‘ë¶„ë¥˜',
        y='í‰ê· ê°’',
        color='ë¬¸í•­ìœ í˜•',
        barmode='group',
        text='í‰ê· ê°’',
        height=450,
        title="ì¤‘ë¶„ë¥˜ë³„ ì„œë¹„ìŠ¤ í‰ê°€/íš¨ê³¼/ë§Œì¡±ë„ (A/B/C) í‰ê· ê°’"
    )
    fig.update_traces(texttemplate='%{text:.1f}', textposition='outside')
    fig.update_yaxes(range=[0,100])
    return fig

def page_segment_analysis(df):
    st.header("ğŸ§© ì´ìš©ì ì„¸ê·¸ë¨¼íŠ¸ ì¡°í•© ë¶„ì„")
    st.markdown("""
    - SQ1~5, DQ1, DQ2, DQ4(1ìˆœìœ„) ì¤‘ **ìµœëŒ€ 3ê°œ** ë¬¸í•­ ì„ íƒ  
    - ì„ íƒí•œ ë³´ê¸° ì¡°í•©ë³„(ì‘ë‹µì 5ëª… ì´ìƒ)ë¡œ Q1~Q6, Q9-D-3, ê³µìµì„±/ê¸°ì—¬ë„(Q7,Q8) ì¤‘ë¶„ë¥˜ë³„ ë§Œì¡±ë„ í‰ê· ì„ **íˆíŠ¸ë§µ**ìœ¼ë¡œ ë¹„êµ
    """)

    def safe_markdown(text, **kwargs):
        # ë§ˆí¬ë‹¤ìš´ í•´ì„ì— ë”°ë¥¸ ì·¨ì†Œì„  ë°©ì§€ (~ â†’ \~ ë˜ëŠ” ëŒ€ì²´)
        escaped = escape_tildes(text, mode="markdown").replace("~~", r"\~\~")
        st.markdown(escaped, **kwargs)

    seg_labels = [o["label"] for o in SEGMENT_OPTIONS]
    sel = st.multiselect("ì„¸ê·¸ë¨¼íŠ¸ ì¡°ê±´ (ìµœëŒ€ 3ê°œ)", seg_labels, default=seg_labels[:2], max_selections=3)
    if not sel:
        st.info("ìµœì†Œ 1ê°œ ì´ìƒì„ ì„ íƒí•˜ì„¸ìš”.")
        return
    selected_keys = [o["key"] for o in SEGMENT_OPTIONS if o["label"] in sel]

    df2 = add_derived_columns(df)

    segment_cols = []
    for key in selected_keys:
        segment_cols.extend(get_segment_columns(df2, key))
    segment_cols = list(dict.fromkeys(segment_cols))

    if not segment_cols:
        st.warning("ì„ íƒí•œ ì„¸ê·¸ë¨¼íŠ¸ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    midcat_prefixes = list(MIDCAT_MAP.values())
    analysis_cols = []
    for p in midcat_prefixes:
        if isinstance(p, list):
            for sub_p in p:
                analysis_cols.extend([c for c in df2.columns if c.startswith(sub_p)])
        else:
            analysis_cols.extend([c for c in df2.columns if c.startswith(p)])
    seg_df = df2[segment_cols + analysis_cols].copy()
    seg_df = seg_df.dropna(subset=segment_cols, how='any')
    for c in segment_cols:
        seg_df[c] = seg_df[c].astype(str)

    group = seg_df.groupby(segment_cols, dropna=False)
    counts = group.size().reset_index(name="ì‘ë‹µììˆ˜")
    counts = counts[counts["ì‘ë‹µììˆ˜"] >= 5]
    if counts.empty:
        st.warning("ì‘ë‹µì 5ëª… ì´ìƒì¸ ì„¸ê·¸ë¨¼íŠ¸ ì¡°í•©ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    midcats = list(MIDCAT_MAP.keys())
    group_means = []

    for idx, row in counts.iterrows():
        key = tuple(row[c] for c in segment_cols)
        gdf = group.get_group(key)
        means = {}
        for cat, prefix in MIDCAT_MAP.items():
            if isinstance(prefix, list):
                cols = []
                for p in prefix:
                    cols += [c for c in gdf.columns if c.startswith(p)]
            else:
                cols = [c for c in gdf.columns if c.startswith(prefix)]
            if not cols:
                means[cat] = None
                continue
            vals = gdf[cols].apply(pd.to_numeric, errors="coerce")
            mean_val = 100 * (vals.mean(axis=1, skipna=True) - 1) / 6
            means[cat] = round(mean_val.mean(), 2)
        seg_info = {col: row[col] for col in segment_cols}
        seg_info.update(means)
        group_means.append(seg_info)

    group_means = pd.DataFrame(group_means)

    segment_cols_filtered = [
        c for c in segment_cols
        if not (c.startswith("SQ2") and "GROUP" not in c) and c != "DQ2_YEARS"
    ]

    merge_keys = segment_cols_filtered
    counts_merge = counts[merge_keys + ["ì‘ë‹µììˆ˜"]]
    group_means = pd.merge(group_means, counts_merge, how='left', on=merge_keys)

    # ì¤‘ë¶„ë¥˜ í‰ê·  ë° ì „ì²´ í‰ê·  ëŒ€ë¹„ í¸ì°¨
    group_means["ì¤‘ë¶„ë¥˜í‰ê· "] = group_means[midcats].mean(axis=1).round(2)
    overall_means = group_means[midcats].mean(axis=0)
    overall_mean_of_means = overall_means.mean()
    group_means["ì „ì²´í‰ê· ëŒ€ë¹„í¸ì°¨"] = (group_means["ì¤‘ë¶„ë¥˜í‰ê· "] - overall_mean_of_means).round(2)

    st.markdown("### ì‘ë‹µì ìˆ˜ ê¸°ì¤€ ìƒìœ„ 10ê°œ ì„¸ê·¸ë¨¼íŠ¸ ì¡°í•©ì˜ ì¤‘ë¶„ë¥˜ ë§Œì¡±ë„ í”„ë¡œíŒŒì¼ ë¹„êµ")
    top_n = 10
    top_df = group_means.nlargest(top_n, "ì‘ë‹µììˆ˜").copy()

    overall_profile = group_means[midcats].mean(axis=0)
    overall_vals = [overall_profile.get(mc, overall_profile.mean()) for mc in midcats]
    overall_closed = overall_vals + [overall_vals[0]]
    cats_closed = midcats + [midcats[0]]

    fig_radar = go.Figure()
    fig_radar.add_trace(go.Scatterpolar(
        r=overall_closed,
        theta=cats_closed,
        fill=None,
        name="ì „ì²´ í‰ê· ",
        line=dict(dash="dash", width=5, color="black"),
        opacity=0.5
    ))

    colors = DEFAULT_PALETTE
    for i, (_, row) in enumerate(top_df.iterrows()):
        combo_label = " | ".join([str(row[c]) for c in segment_cols_filtered])
        vals = [row[mc] if not pd.isna(row[mc]) else overall_profile.get(mc, overall_profile.mean()) for mc in midcats]
        vals_closed = vals + [vals[0]]
        fig_radar.add_trace(go.Scatterpolar(
            r=vals_closed,
            theta=cats_closed,
            fill=None,
            name=f"{combo_label} (n={int(row['ì‘ë‹µììˆ˜'])})",
            hovertemplate="%{theta}: %{r:.1f}<extra></extra>",
            marker=dict(color=colors[i % len(colors)]),
            opacity=0.9
        ))

    fig_radar.update_layout(
        polar=dict(radialaxis=dict(range=[50, 100])),
        title=f"ìƒìœ„ {min(top_n, len(top_df))}ê°œ ì„¸ê·¸ë¨¼íŠ¸ ì¡°í•© ì¤‘ë¶„ë¥˜ ë§Œì¡±ë„ í”„ë¡œíŒŒì¼ vs ì „ì²´ í‰ê· ",
        height=500,
        showlegend=True,
        legend=dict(orientation="v", y=0.85, x=1.02)
    )
    st.plotly_chart(fig_radar, use_container_width=True)

    # ë£° ê¸°ë°˜ ìš”ì•½
    st.markdown("#### ë£° ê¸°ë°˜ ìš”ì•½")
    overall_profile_dict = {mc: overall_profile.get(mc, 0) for mc in midcats}
    high_low_summary = interpret_midcategory_scores(df) if 'interpret_midcategory_scores' in globals() else ""
    safe_markdown(high_low_summary)

    # GPT ê¸°ë°˜ í•´ì„ (ë ˆì´ë”)
    st.markdown("#### GPT ìƒì„±í˜• í•´ì„")
    combos = []
    for _, row in top_df.iterrows():
        combo_label = " | ".join([str(row[c]) for c in segment_cols_filtered])
        profile = {mc: row.get(mc, overall_profile.get(mc, overall_profile.mean())) for mc in midcats}
        combos.append({"label": combo_label, "n": int(row["ì‘ë‹µììˆ˜"]), "profile": profile})
    prompt = build_radar_prompt(overall_profile_dict, combos)
    insight_text = call_gpt_for_insight(prompt)
    insight_text = insight_text.replace("~", "-")
    render_insight_card("GPT ìƒì„±í˜• í•´ì„", insight_text, key="segment-radar")

    # ì¡°í•©ëª… ìƒì„± ë° delta ê³„ì‚° (ì „ì²´ í‰ê·  ê¸°ì¤€)
    group_means["ì¡°í•©"] = group_means.apply(lambda r: " | ".join([str(r[c]) for c in segment_cols_filtered]), axis=1)
    for mc in midcats:
        group_means[f"{mc}_delta"] = group_means[mc] - overall_means[mc]

    # íˆíŠ¸ë§µ: ì¤‘ë¶„ë¥˜ í‰ê· 
    st.markdown("### íˆíŠ¸ë§µ + ì „ì²´ í‰ê·  ëŒ€ë¹„ ì¤‘ë¶„ë¥˜ë³„ í¸ì°¨ íˆíŠ¸ë§µ")
    heatmap_plot = group_means.set_index("ì¡°í•©")[midcats]
    fig_abs = px.imshow(
        heatmap_plot,
        text_auto=True,
        aspect="auto",
        color_continuous_scale="Blues",
        title="ì„¸ê·¸ë¨¼íŠ¸ ì¡°í•©ë³„ ì¤‘ë¶„ë¥˜ í‰ê· ",
        labels=dict(x="ì¤‘ë¶„ë¥˜", y="ì„¸ê·¸ë¨¼íŠ¸ ì¡°í•©", color="í‰ê· ì ìˆ˜")
    )
    st.plotly_chart(fig_abs, use_container_width=True)

    st.markdown("#### íˆíŠ¸ë§µ ë£° ê¸°ë°˜ ìš”ì•½")
    st.write("**ì „ì²´ í‰ê·  ëŒ€ë¹„ ì¤‘ë¶„ë¥˜ í‰ê·  í”„ë¡œíŒŒì¼**")

    st.markdown("#### GPT ìƒì„±í˜• í•´ì„ (íˆíŠ¸ë§µ)")
    heatmap_table = group_means[[*segment_cols_filtered, *midcats, "ì‘ë‹µììˆ˜"]]
    prompt_heat = build_heatmap_prompt(heatmap_table.rename(columns={"ì‘ë‹µììˆ˜": "ì‘ë‹µììˆ˜"}), midcats)
    heat_insight = call_gpt_for_insight(prompt_heat)
    heat_insight = heat_insight.replace("~", "-")
    render_insight_card("GPT ìƒì„±í˜• í•´ì„ (íˆíŠ¸ë§µ)", heat_insight, key="heatmap-insight")

    # ë¸íƒ€ íˆíŠ¸ë§µ
    delta_plot = group_means.set_index("ì¡°í•©")[[f"{mc}_delta" for mc in midcats]]
    delta_plot.columns = midcats
    fig_delta = px.imshow(
        delta_plot,
        text_auto=True,
        aspect="auto",
        color_continuous_scale="RdBu_r",
        title="ì „ì²´ í‰ê·  ëŒ€ë¹„ í¸ì°¨ (Delta)",
        labels=dict(x="ì¤‘ë¶„ë¥˜", y="ì„¸ê·¸ë¨¼íŠ¸ ì¡°í•©", color="í¸ì°¨")
    )
    st.plotly_chart(fig_delta, use_container_width=True)

    st.markdown("#### Delta íˆíŠ¸ë§µ ë£° ê¸°ë°˜ ìš”ì•½")
    delta_summary_parts = []
    for mc in midcats:
        col_delta = f"{mc}_delta"
        if col_delta in group_means:
            top_pos = group_means.nlargest(1, col_delta)
            top_neg = group_means.nsmallest(1, col_delta)
            if not top_pos.empty:
                delta_summary_parts.append(f"{mc}ì—ì„œ ê°€ì¥ ë†’ì€ í¸ì°¨: {top_pos.iloc[0]['ì¡°í•©']} (+{top_pos.iloc[0][col_delta]:.1f})")
            if not top_neg.empty:
                delta_summary_parts.append(f"{mc}ì—ì„œ ê°€ì¥ ë‚®ì€ í¸ì°¨: {top_neg.iloc[0]['ì¡°í•©']} ({top_neg.iloc[0][col_delta]:.1f})")
    st.text("ï¼›".join(delta_summary_parts) if delta_summary_parts else "ì˜ë¯¸ ìˆëŠ” í¸ì°¨ë¥¼ ë°œê²¬í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    st.markdown("#### GPT ìƒì„±í˜• í•´ì„ (Delta)")
    delta_df_for_prompt = group_means.set_index("ì¡°í•©")
    prompt_delta = build_delta_prompt(delta_df_for_prompt, midcats)
    delta_insight = call_gpt_for_insight(prompt_delta)
    delta_insight = delta_insight.replace("~", "-")
    render_insight_card("GPT ìƒì„±í˜• í•´ì„ (ë¸íƒ€ íˆíŠ¸ë§µ)", delta_insight, key="delta-heatmap-insight")

#ì‹ ë¢°êµ¬ê°„ í¬í•¨ í¸ì°¨ ë°” ì°¨íŠ¸ í•´ì„

    st.markdown("### ì „ì²´ í‰ê·  ëŒ€ë¹„ í¸ì°¨ì™€ ê°„ì´ ì‹ ë¢°êµ¬ê°„ (ì¤‘ë¶„ë¥˜ë³„)")
    for mc in midcats[:2]:
        subset = group_means.nlargest(10, "ì‘ë‹µììˆ˜").copy()
        subset["delta"] = subset[mc] - overall_means[mc]
        subset["se"] = np.sqrt((subset[mc] * (100 - subset[mc]) / subset["ì‘ë‹µììˆ˜"]).clip(lower=0))
        fig_ci = go.Figure()
        fig_ci.add_trace(go.Bar(
            x=subset["ì¡°í•©"],
            y=subset["delta"],
            error_y=dict(type="data", array=subset["se"]),
            name=f"{mc} í¸ì°¨"
        ))
        fig_ci.add_hline(y=0, line_dash="dash", line_color="black")
        fig_ci.update_layout(
            title=f"{mc} ì „ì²´ í‰ê·  ëŒ€ë¹„ í¸ì°¨ (ì‹ ë¢°êµ¬ê°„, ìƒìœ„ 5ê°œ ì¡°í•©)",
            yaxis_title="í¸ì°¨",
            height=350,
            margin=dict(t=40, b=60)
        )
        st.plotly_chart(fig_ci, use_container_width=True)
        st.markdown(f"#### '{mc}' í¸ì°¨ ì‹ ë¢°ë„ í•´ì„")
        # ë£° ê¸°ë°˜: 0ì„ ë²—ì–´ë‚˜ëŠ”ì§€ ì²´í¬
        ci_summary = []
        subset_local = subset  # ê¸°ì¡´ ë³€ìˆ˜
        for _, r in subset_local.iterrows():
            combo = r["ì¡°í•©"]
            delta = r["delta"]
            se = r["se"]
            ci_lower = delta - se
            ci_upper = delta + se
            signif = "ìœ ì˜ë¯¸" if not (ci_lower <= 0 <= ci_upper) else "ë¶ˆí™•ì‹¤"
            ci_summary.append(f"{combo}: í¸ì°¨ {delta:.1f}, SE {se:.2f} ({signif})")
        safe_markdown("ï¼›".join(ci_summary))

        st.markdown("#### GPT ìƒì„±í˜• í•´ì„ (ì‹ ë¢°êµ¬ê°„)")
        prompt_ci = build_ci_prompt(subset_local, mc)
        ci_insight = call_gpt_for_insight(prompt_ci)
        render_insight_card("GPT ìƒì„±í˜• í•´ì„ (ì‹ ë¢°êµ¬ê°„)", ci_insight, key="ci-insight")

def show_basic_strategy_insights(df):
    st.subheader("1. ì´ìš© ëª©ì  (DQ4 ê³„ì—´) Ã— ì „ë°˜ ë§Œì¡±ë„ (ì¤‘ë¶„ë¥˜ ê¸°ì¤€ ë ˆì´ë”)")
    purpose_col = None
    for c in df.columns:
        if "DQ4" in c and "1ìˆœìœ„" in c:
            purpose_col = c
            break
    if purpose_col is None:
        for c in df.columns:
            if "DQ4" in c:
                purpose_col = c
                break

    if purpose_col is None:
        st.warning("ì´ìš© ëª©ì  ê´€ë ¨ ì»¬ëŸ¼(DQ4 ê³„ì—´)ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ì „ë°˜ ë§Œì¡±ë„ ëŒ€ë¹„ ë ˆì´ë”ë¥¼ ê·¸ë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        overall_mid_scores = compute_midcategory_scores(df)
        if overall_mid_scores.empty:
            st.warning("ì¤‘ë¶„ë¥˜ ì ìˆ˜ ê³„ì‚°ì— í•„ìš”í•œ ë¬¸í•­ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")
        else:
            midcats = list(overall_mid_scores.index)
            purpose_counts = df[purpose_col].dropna().astype(str).value_counts()

            default_n = min(5, len(purpose_counts))
            top_n = st.session_state.get("strategy_radar_top_n_main", default_n)
            top_purposes = purpose_counts.nlargest(top_n).index.tolist()

            fig = go.Figure()
            overall_vals = [overall_mid_scores.get(m, 0) for m in midcats]
            fig.add_trace(go.Scatterpolar(
                r=overall_vals + [overall_vals[0]],
                theta=midcats + [midcats[0]],
                fill=None,
                name="ì „ì²´ í‰ê· ",
                line=dict(dash='dash', width=2),
                opacity=1
            ))

            colors = DEFAULT_PALETTE
            for i, purpose in enumerate(top_purposes):
                subset = df[df[purpose_col].astype(str) == purpose]
                if len(subset) < 5:
                    continue
                purpose_scores = compute_midcategory_scores(subset)
                vals = [purpose_scores.get(m, overall_mid_scores.get(m, 0)) for m in midcats]
                fig.add_trace(go.Scatterpolar(
                    r=vals + [vals[0]],
                    theta=midcats + [midcats[0]],
                    fill=None,
                    name=f"{purpose} (n={int(purpose_counts[purpose])})",
                    hovertemplate="%{theta}: %{r:.1f}<extra></extra>",
                    marker=dict(color=colors[i % len(colors)]),
                    opacity=0.6
                ))

            fig.update_layout(
                polar=dict(radialaxis=dict(range=[50, 100])),
                title=f"ìƒìœ„ {len(top_purposes)}ê°œ ì´ìš© ëª©ì ë³„ ì¤‘ë¶„ë¥˜ ë§Œì¡±ë„ vs ì „ì²´ í‰ê· ",
                height=450,
                legend=dict(orientation="v", x=1.02, y=0.9)
            )
            st.plotly_chart(fig, use_container_width=True)

            top_n = st.number_input(
                "ë ˆì´ë”ì— í‘œì‹œí•  ìƒìœ„ ì´ìš© ëª©ì  ê°œìˆ˜",
                min_value=1,
                max_value=max(1, len(purpose_counts)),
                value=default_n,
                step=1,
                key="strategy_radar_top_n_main"
            )

            top_purposes = purpose_counts.nlargest(top_n).index.tolist()
            summary_rows = []
            for purpose in top_purposes:
                subset = df[df[purpose_col].astype(str) == purpose]
                if len(subset) < 5:
                    continue
                purpose_scores = compute_midcategory_scores(subset)
                row = {"ì´ìš©ëª©ì ": purpose, "ì‘ë‹µììˆ˜": int(purpose_counts[purpose])}
                for m in midcats:
                    row[f"{m} (ëª©ì )"] = round(purpose_scores.get(m, overall_mid_scores.get(m, 0)), 1)
                    row[f"{m} (ì „ì²´ í‰ê· )"] = round(overall_mid_scores.get(m, 0), 1)
                summary_rows.append(row)
            if summary_rows:
                summary_df = pd.DataFrame(summary_rows)
                st.markdown("#### ìƒìœ„ ì´ìš© ëª©ì ë³„ ì¤‘ë¶„ë¥˜ í”„ë¡œíŒŒì¼ ìš”ì•½")
                st.dataframe(summary_df)

    st.subheader("2. ì´ìš© ëª©ì  (DQ4 ê³„ì—´) Ã— ì„¸ë¶€ í•­ëª© íš¨ê³¼ (Q6-B ê³„ì—´)")
    q6b_cols = [c for c in df.columns if c.startswith("Q6-B")]
    if purpose_col is None:
        st.warning("ì´ìš© ëª©ì  ì»¬ëŸ¼ì´ ì—†ì–´ Q6-B ê³„ì—´ íš¨ê³¼ë¥¼ ì´ìš© ëª©ì ë³„ë¡œ ë¹„êµí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    elif not q6b_cols:
        st.warning("Q6-B ê³„ì—´ ë¬¸í•­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        purpose_counts = df[purpose_col].dropna().astype(str).value_counts()
        effect_rows = []
        for purpose in purpose_counts.index:
            subset = df[df[purpose_col].astype(str) == purpose]
            if len(subset) < 5:
                continue
            vals = subset[q6b_cols].apply(pd.to_numeric, errors='coerce')
            scaled = 100 * (vals.mean(axis=1, skipna=True) - 1) / 6
            mean_effect = scaled.mean()
            effect_rows.append({
                "ì´ìš©ëª©ì ": purpose,
                "Q6-B ê³„ì—´ íš¨ê³¼ í‰ê· (0~100)": round(mean_effect, 2),
                "ì‘ë‹µììˆ˜": len(scaled.dropna())
            })
        if effect_rows:
            effect_df = pd.DataFrame(effect_rows).sort_values("Q6-B ê³„ì—´ íš¨ê³¼ í‰ê· (0~100)", ascending=False)
            fig = px.bar(
                effect_df,
                x="ì´ìš©ëª©ì ",
                y="Q6-B ê³„ì—´ íš¨ê³¼ í‰ê· (0~100)",
                text="Q6-B ê³„ì—´ íš¨ê³¼ í‰ê· (0~100)",
                title="ì´ìš© ëª©ì ë³„ Q6-B ê³„ì—´ ì„¸ë¶€ íš¨ê³¼ í‰ê·  ë¹„êµ",
                hover_data=["ì‘ë‹µììˆ˜"]
            )
            fig.update_traces(texttemplate="%{text:.1f}", textposition="outside")
            st.plotly_chart(fig, use_container_width=True)
            st.dataframe(effect_df)
        else:
            st.info("ì´ìš© ëª©ì ë³„ë¡œ ì¶©ë¶„í•œ ì‘ë‹µì´ ì—†ì–´ Q6-B íš¨ê³¼ ë¹„êµë¥¼ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    st.subheader("3. ì£¼ì´ìš©ì„œë¹„ìŠ¤ë³„ ì¤‘ë¶„ë¥˜ ë§Œì¡±ë„ (SQ5 ê¸°ì¤€)")
    service_col = None
    for candidate in df.columns:
        if "SQ5" in candidate or "ì£¼ë¡œ ì´ìš© ì„œë¹„ìŠ¤" in candidate:
            service_col = candidate
            break
    if service_col is None:
        st.warning("ì£¼ì´ìš©ì„œë¹„ìŠ¤ ê´€ë ¨ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ì¤‘ë¶„ë¥˜ ë§Œì¡±ë„ ë¹„êµë¥¼ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        services = df[service_col].dropna().astype(str).unique()
        overall_mid_scores = compute_midcategory_scores(df)
        midcats = list(overall_mid_scores.index)
        plot_data = []
        for service in services:
            subset = df[df[service_col].astype(str) == service]
            if len(subset) < 5:
                continue
            service_scores = compute_midcategory_scores(subset)
            for m in midcats:
                plot_data.append({
                    "ì£¼ì´ìš©ì„œë¹„ìŠ¤": service,
                    "ì¤‘ë¶„ë¥˜": m,
                    "ì„œë¹„ìŠ¤ë³„ ë§Œì¡±ë„": service_scores.get(m, None),
                    "ì „ì²´ í‰ê· ": overall_mid_scores.get(m, None)
                })
        if plot_data:
            plot_df = pd.DataFrame(plot_data)
            fig = px.bar(
                plot_df,
                x="ì¤‘ë¶„ë¥˜",
                y="ì„œë¹„ìŠ¤ë³„ ë§Œì¡±ë„",
                color="ì£¼ì´ìš©ì„œë¹„ìŠ¤",
                barmode="group",
                title="ì£¼ì´ìš©ì„œë¹„ìŠ¤ë³„ ì¤‘ë¶„ë¥˜ ë§Œì¡±ë„ ë¹„êµ",
                text="ì„œë¹„ìŠ¤ë³„ ë§Œì¡±ë„"
            )
            avg_df = plot_df.drop_duplicates(subset=["ì¤‘ë¶„ë¥˜"])[["ì¤‘ë¶„ë¥˜", "ì „ì²´ í‰ê· "]]
            fig.add_trace(go.Scatter(
                x=avg_df["ì¤‘ë¶„ë¥˜"],
                y=avg_df["ì „ì²´ í‰ê· "],
                mode="lines+markers",
                name="ì „ì²´ í‰ê· ",
                line=dict(dash="dash"),
                hovertemplate="%{x}: %{y:.1f}<extra></extra>"
            ))
            for trace in fig.data:
                if getattr(trace, "type", None) == "bar":
                    trace.texttemplate = '%{text:.1f}'
                    trace.textposition = 'outside'
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("ì£¼ì´ìš©ì„œë¹„ìŠ¤ë³„ë¡œ ë¹„êµí•  ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.subheader("4. ë¶ˆì´ìš© ì‚¬ìœ  Ã— ì¤‘ë¶„ë¥˜ ë§Œì¡±ë„")
    reason_col = None
    for candidate in df.columns:
        low = candidate.lower()
        if "ë¶ˆì´ìš©" in candidate or "ì´ìš© ì•ˆí•¨" in low or "ì´ìš©í•˜ì§€" in low or "ì‚¬ìš© ì•ˆí•¨" in low:
            reason_col = candidate
            break
    if reason_col is None:
        st.warning("ë¶ˆì´ìš© ì‚¬ìœ  ê´€ë ¨ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        reasons = df[reason_col].dropna().astype(str).unique()
        rows_exist = False
        for reason in reasons:
            subset = df[df[reason_col].astype(str) == reason]
            if len(subset) < 5:
                continue
            reason_scores = compute_midcategory_scores(subset)
            if reason_scores.empty:
                continue
            rows_exist = True
            plot_df = pd.DataFrame({
                "ì¤‘ë¶„ë¥˜": list(reason_scores.index),
                "ë§Œì¡±ë„": [reason_scores.get(m, None) for m in reason_scores.index]
            })
            fig = px.bar(
                plot_df,
                x="ì¤‘ë¶„ë¥˜",
                y="ë§Œì¡±ë„",
                text="ë§Œì¡±ë„",
                title=f"ë¶ˆì´ìš© ì‚¬ìœ  '{reason}' ë³„ ì¤‘ë¶„ë¥˜ ë§Œì¡±ë„",
            )
            fig.update_traces(texttemplate="%{text:.1f}", textposition="outside")
            st.plotly_chart(fig, use_container_width=True)
        if not rows_exist:
            st.info("ë¶ˆì´ìš© ì‚¬ìœ ë³„ë¡œ ë¹„êµí•  ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.subheader("5. ì´ìš© ëª©ì  (DQ4 ê³„ì—´) Ã— ìš´ì˜ì‹œê°„ ë§Œì¡±ë„ (Q7-D-7)")
    time_sat_col = None
    for c in df.columns:
        if c.upper().startswith("Q7-D-7"):
            time_sat_col = c
            break
        if "ìš´ì˜ì‹œê°„" in c or "ì‹œê°„ ë§Œì¡±ë„" in c:
            time_sat_col = c
            break

    if purpose_col is None or time_sat_col is None:
        st.warning("ì´ìš© ëª©ì  ë˜ëŠ” ìš´ì˜ì‹œê°„ ë§Œì¡±ë„ ë¬¸í•­ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ë¹„êµí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        purpose_counts = df[purpose_col].dropna().astype(str).value_counts()
        rows = []
        for purpose in purpose_counts.index:
            subset = df[df[purpose_col].astype(str) == purpose]
            if subset.empty:
                continue
            vals = pd.to_numeric(subset[time_sat_col], errors='coerce').dropna().astype(float)
            if vals.empty:
                continue
            mean_score = vals.mean()
            rows.append({
                "ì´ìš©ëª©ì ": purpose,
                "ìš´ì˜ì‹œê°„ ë§Œì¡±ë„ í‰ê· ": round(mean_score, 2),
                "ì‘ë‹µììˆ˜": len(vals)
            })
        if rows:
            time_df = pd.DataFrame(rows).sort_values("ìš´ì˜ì‹œê°„ ë§Œì¡±ë„ í‰ê· ", ascending=False)
            fig = px.bar(
                time_df,
                x="ì´ìš©ëª©ì ",
                y="ìš´ì˜ì‹œê°„ ë§Œì¡±ë„ í‰ê· ",
                text="ìš´ì˜ì‹œê°„ ë§Œì¡±ë„ í‰ê· ",
                title="ì´ìš© ëª©ì ë³„ ìš´ì˜ì‹œê°„(ê¸°ëŒ€ ëŒ€ë¹„) ë§Œì¡±ë„",
                hover_data=["ì‘ë‹µììˆ˜"]
            )
            fig.update_traces(texttemplate="%{text:.1f}", textposition="outside")
            st.plotly_chart(fig, use_container_width=True)
            st.dataframe(time_df)
        else:
            st.info("ë¹„êµ ê°€ëŠ¥í•œ ì´ìš©ëª©ì ë³„ ìš´ì˜ì‹œê°„ ë§Œì¡±ë„ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì‹¤í–‰ ì—”íŠ¸ë¦¬
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="ê³µê³µë„ì„œê´€ ì„¤ë¬¸ ì‹œê°í™” ëŒ€ì‹œë³´ë“œ",
    layout="wide"
)

mode = st.sidebar.radio("ë¶„ì„ ëª¨ë“œ", ["ê¸°ë³¸ ë¶„ì„", "ì‹¬í™” ë¶„ì„", "ì „ëµ ì¸ì‚¬ì´íŠ¸(ê¸°ë³¸)", "ìì—°ì–´ ì§ˆì˜"])

uploaded = st.file_uploader("ğŸ“‚ ì—‘ì…€(.xlsx) íŒŒì¼ ì—…ë¡œë“œ", type=["xlsx"])
if not uploaded:
    st.info("ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
    st.stop()

try:
    df = pd.read_excel(uploaded)
    st.success("âœ… ì—…ë¡œë“œ ì™„ë£Œ")
except Exception as e:
    st.error(f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
    st.stop()

if mode == "ê¸°ë³¸ ë¶„ì„":
    tabs = st.tabs([
        "ğŸ‘¤ ì‘ë‹µì ì •ë³´",
        "ğŸ“ˆ ë§Œì¡±ë„ ê¸°ë³¸ ì‹œê°í™”",
        "ğŸ—ºï¸ ìì¹˜êµ¬ êµ¬ì„± ë¬¸í•­",
        "ğŸ“Š ë„ì„œê´€ ì´ìš©ì–‘íƒœ ë¶„ì„",
        "ğŸ–¼ï¸ ë„ì„œê´€ ì´ë¯¸ì§€ ë¶„ì„",
        "ğŸ‹ï¸ ë„ì„œê´€ ê°•ì•½ì  ë¶„ì„",
    ])

    with tabs[0]:
        page_home(df)

    with tabs[1]:
        page_basic_vis(df)

    with tabs[2]:
        st.header("ğŸ—ºï¸ ìì¹˜êµ¬ êµ¬ì„± ë¬¸í•­ ë¶„ì„")
        sub_tabs = st.tabs([
            "7ì  ì²™ë„ ì‹œê°í™”",
            "ë‹¨ë¬¸ ì‘ë‹µ ë¶„ì„",
            "ì¥ë¬¸ ì„œìˆ í˜• ë¶„ì„"
        ])
        with sub_tabs[0]:
            st.subheader("ìì¹˜êµ¬ êµ¬ì„± ë¬¸í•­ (7ì  ì²™ë„)")
            subregion_cols = [c for c in df.columns if "Q9-D-" in c]
            if not subregion_cols:
                st.error("Q9-D- ë¡œ ì‹œì‘í•˜ëŠ” ë¬¸í•­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                for idx, col in enumerate(subregion_cols):
                    bar, tbl = plot_stacked_bar_with_table(df, col)
                    st.markdown(f"##### {col}")
                    render_chart_and_table(bar, tbl, col, key_prefix=f"subregion-{idx}")
        with sub_tabs[1]:
            page_short_keyword(df)
        with sub_tabs[2]:
            st.subheader("ì¥ë¬¸ ì„œìˆ í˜• ë¶„ì„ (Q9-DS-5)")
            long_cols = [c for c in df.columns if "Q9-DS-5" in c]
            if not long_cols:
                st.warning("Q9-DS-5 ê´€ë ¨ ë¬¸í•­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                answers = df[long_cols[0]].dropna().astype(str).tolist()
                df_long = process_answers(answers)
                show_short_answer_keyword_analysis(df_long)

    with tabs[3]:
        st.header("ğŸ“Š ë„ì„œê´€ ì´ìš©ì–‘íƒœ ë¶„ì„")
        sub_tabs = st.tabs(["DQ1~5", "DQ6 ê³„ì—´"])
        with sub_tabs[0]:
            fig1, tbl1, q1 = plot_dq1(df)
            render_chart_and_table(fig1, tbl1, q1, key_prefix="dq1")

            fig2, tbl2, q2 = plot_dq2(df)
            render_chart_and_table(fig2, tbl2, q2, key_prefix="dq2")

            fig3, tbl3, q3 = plot_dq3(df)
            render_chart_and_table(fig3, tbl3, q3, key_prefix="dq3")

            fig4, tbl4, q4 = plot_dq4_bar(df)
            render_chart_and_table(fig4, tbl4, q4, key_prefix="dq4")

            fig5, tbl5, q5 = plot_dq5(df)
            render_chart_and_table(fig5, tbl5, q5, key_prefix="dq5")
        with sub_tabs[1]:
            st.subheader("DQ6 ê³„ì—´ ë¬¸í•­ ë¶„ì„")
            dq6_cols = [c for c in df.columns if c.startswith("DQ6")]
            if not dq6_cols:
                st.warning("DQ6 ê³„ì—´ ë¬¸í•­ì´ ì—†ìŠµë‹ˆë‹¤.")
            else:
                for col in dq6_cols:
                    st.markdown(f"### {col}")
                    if col == dq6_cols[0]:
                        multi = df[col].dropna().astype(str).str.split(',')
                        exploded = multi.explode().str.strip()
                        counts = exploded.value_counts()
                        percent = (counts / counts.sum() * 100).round(1)

                        fig = go.Figure(go.Bar(
                            x=counts.values, y=counts.index,
                            orientation='h', text=counts.values,
                            textposition='outside', marker_color=get_qualitative_colors(len(counts))
                        ))
                        fig.update_layout(
                            title=col,
                            xaxis_title="ì‘ë‹µ ìˆ˜",
                            yaxis_title="ì„œë¹„ìŠ¤",
                            height=400,
                            margin=dict(t=50, b=100)
                        )
                        table_df = pd.DataFrame({
                            'ì‘ë‹µ ìˆ˜': counts,
                            'ë¹„ìœ¨ (%)': percent
                        }).T
                        render_chart_and_table(fig, table_df, col, key_prefix="dq6")
                    else:
                        bar, tbl = plot_categorical_stacked_bar(df, col)
                        render_chart_and_table(bar, tbl, col, key_prefix="dq6")

    with tabs[4]:
        st.header("ğŸ–¼ï¸ ë„ì„œê´€ ì´ë¯¸ì§€ ë¶„ì„")
        fig, tbl = plot_likert_diverging(df, prefix="DQ7-E")
        if fig is not None:
            render_chart_and_table(fig, tbl, "DQ7-E ì´ë¯¸ì§€ ë¶„í¬", key_prefix="image-diverge")
        else:
            st.warning("DQ7-E ë¬¸í•­ì´ ì—†ìŠµë‹ˆë‹¤.")

    with tabs[5]:
        st.header("ğŸ‹ï¸ ë„ì„œê´€ ê°•ì•½ì  ë¶„ì„")
        fig8, tbl8, q8 = plot_pair_bar(df, "DQ8")
        if fig8 is not None:
            render_chart_and_table(fig8, tbl8, q8, key_prefix="strength")
        else:
            st.warning("DQ8 ë¬¸í•­ì´ ì—†ìŠµë‹ˆë‹¤.")
        fig9, tbl9, q9 = plot_pair_bar(df, "DQ9")
        if fig9 is not None:
            render_chart_and_table(fig9, tbl9, q9, key_prefix="weakness")
        else:
            st.warning("DQ9 ë¬¸í•­ì´ ì—†ìŠµë‹ˆë‹¤.")

elif mode == "ì‹¬í™” ë¶„ì„":
    tabs = st.tabs(["ê³µí†µ ì‹¬í™” ë¶„ì„(ì „ì²´)", "ê³µí†µ ì‹¬í™” ë¶„ì„(ì˜ì—­)", "ì´ìš©ì ì„¸ê·¸ë¨¼íŠ¸ ì¡°í•© ë¶„ì„"])
    with tabs[0]:
        st.header("ğŸ” ê³µí†µ ì‹¬í™” ë¶„ì„(ì „ì²´)")
        st.subheader("ì¤‘ë¶„ë¥˜ë³„ ì „ì²´ ë§Œì¡±ë„ (ë ˆì´ë” ì°¨íŠ¸ ë° í‰ê· ê°’)")
        radar = plot_midcategory_radar(df)
        if radar is not None:
            st.plotly_chart(radar, use_container_width=True)
            tbl_avg = midcategory_avg_table(df)
            if not tbl_avg.empty:
                show_table(tbl_avg, "ì¤‘ë¶„ë¥˜ë³„ í‰ê·  ì ìˆ˜")
                st.markdown("---")
            else:
                st.warning("ì¤‘ë¶„ë¥˜ í‰ê· ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.warning("í•„ìš”í•œ ë¬¸í•­ì´ ì—†ì–´ ì¤‘ë¶„ë¥˜ ì ìˆ˜ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        st.subheader("ì¤‘ë¶„ë¥˜ ë‚´ ë¬¸í•­ë³„ í¸ì°¨")
        mid_scores = compute_midcategory_scores(df)
        if mid_scores.empty:
            st.warning("ì¤‘ë¶„ë¥˜ ë¬¸í•­ì´ ì—†ì–´ í¸ì°¨ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            for mid in mid_scores.index:
                fig, table_df = plot_within_category_bar(df, mid)
                if fig is None:
                    continue
                st.markdown(f"### {mid}")
                st.plotly_chart(fig, use_container_width=True)
                if table_df is not None:
                    show_table(
                        table_df.reset_index().rename(columns={"index": "ë¬¸í•­"}),
                        f"{mid} í•­ëª©ë³„ í¸ì°¨"
                    )
                    st.markdown("---")
    with tabs[1]:
        st.header("ğŸ” ê³µí†µ ì‹¬í™” ë¶„ì„(ì˜ì—­ë³„ A/B/C ë¹„êµ)")
        df_mean = get_abc_category_means(df)
        radar_fig = plot_abc_radar(df_mean)
        bar_fig = plot_abc_grouped_bar(df_mean)

        st.subheader("ì¤‘ë¶„ë¥˜ë³„ ì„œë¹„ìŠ¤ í‰ê°€/íš¨ê³¼/ë§Œì¡±ë„ (A/B/C) ë ˆì´ë” ì°¨íŠ¸")
        st.plotly_chart(radar_fig, use_container_width=True)

        st.subheader("ì¤‘ë¶„ë¥˜ë³„ ì„œë¹„ìŠ¤ í‰ê°€/íš¨ê³¼/ë§Œì¡±ë„ (A/B/C) ë¬¶ìŒ(bar) ì°¨íŠ¸")
        st.plotly_chart(bar_fig, use_container_width=True)

        st.markdown("#### ìƒì„¸ ë°ì´í„°")
        st.dataframe(df_mean)
    with tabs[2]:
        page_segment_analysis(df)
        

elif mode == "ì „ëµ ì¸ì‚¬ì´íŠ¸(ê¸°ë³¸)":
    st.header("ğŸ§  ì „ëµ ì¸ì‚¬ì´íŠ¸ (ê¸°ë³¸)")
    show_basic_strategy_insights(df)
elif mode == "ìì—°ì–´ ì§ˆì˜":
    st.header("ğŸ—£ï¸ ìì—°ì–´ ì§ˆë¬¸ ê¸°ë°˜ ìë™ ë¶„ì„")
    st.markdown("ì˜ˆì‹œ: 'í˜¼ì ì´ìš©í•˜ëŠ” ì‚¬ëŒë“¤ì˜ ì—°ë ¹ëŒ€ ë¶„í¬ ë³´ì—¬ì£¼ê³  ì£¼ë¡œ ê°€ëŠ” ë„ì„œê´€ë³„ ì¤‘ë¶„ë¥˜ ë§Œì¡±ë„ ê°•ì /ì•½ì  ë¹„êµí•´ì¤˜.'")
    question = st.text_input("ìì—°ì–´ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: í˜¼ì ì´ìš©ìë“¤ì˜ ì£¼ ì´ìš© ë„ì„œê´€ë³„ ë§Œì¡±ë„ ë¹„êµí•˜ê³  ê°•ì  ì•½ì  ì•Œë ¤ì¤˜")
    if question:
        handle_nl_question(df, question)